{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tidyverse\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.1     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Loading required package: compiler\n",
      "\n",
      "Loading required package: raster\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "\n",
      "Attaching package: ‘raster’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Loading required package: hsdar\n",
      "\n",
      "Loading required package: rgdal\n",
      "\n",
      "Please note that rgdal will be retired during 2023,\n",
      "plan transition to sf/stars/terra functions using GDAL and PROJ\n",
      "at your earliest convenience.\n",
      "See https://r-spatial.org/r/2022/04/12/evolution.html and https://github.com/r-spatial/evolution\n",
      "rgdal: version: 1.6-6, (SVN revision 1201)\n",
      "Geospatial Data Abstraction Library extensions to R successfully loaded\n",
      "Loaded GDAL runtime: GDAL 3.4.3, released 2022/04/22\n",
      "Path to GDAL shared files: /usr/share/gdal\n",
      "GDAL binary built with GEOS: TRUE \n",
      "Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821]\n",
      "Path to PROJ shared files: /home/krbundy/.local/share/proj:/usr/share/proj\n",
      "PROJ CDN enabled: FALSE\n",
      "Linking to sp version:1.6-0\n",
      "To mute warnings of possible GDAL/OSR exportToProj4() degradation,\n",
      "use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n",
      "\n",
      "Loading required package: signal\n",
      "\n",
      "\n",
      "Attaching package: ‘signal’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, poly\n",
      "\n",
      "\n",
      "Loading required package: caret\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "Loading required package: Boruta\n",
      "\n",
      "\n",
      "###################################\n",
      "  This is hsdar 1.0.4\n",
      "  To get citation entry type\n",
      "      'citation(\"hsdar\")'\n",
      "###################################\n",
      "\n",
      "\n",
      "Attaching package: ‘hsdar’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    nbands\n",
      "\n",
      "\n",
      "Loading required package: spectrolab\n",
      "\n",
      "spectrolab version: 0.0.18\n",
      "\n",
      "Please cite:\n",
      "Meireles J, Schweiger A, Cavender-Bares J (2017). spectrolab: Class\n",
      "and Methods for Spectral Data in R. doi:10.5281/zenodo.3934575\n",
      "<https://doi.org/10.5281/zenodo.3934575>, R package version 0.0.18,\n",
      "<https://CRAN.R-project.org/package=spectrolab>.DOI: https://doi.org/10.5281/zenodo.3934575\n",
      "\n",
      "\n",
      "Attaching package: ‘spectrolab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:hsdar’:\n",
      "\n",
      "    spectra\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:signal’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    sd, smooth, var\n",
      "\n",
      "\n",
      "Loading required package: ranger\n",
      "\n",
      "Loading required package: stringi\n",
      "\n",
      "Loading required package: rjson\n",
      "\n",
      "Loading required package: snow\n",
      "\n",
      "Loading required package: doSNOW\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "\n",
      "Attaching package: ‘foreach’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    accumulate, when\n",
      "\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: rasterVis\n",
      "\n",
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:signal’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, custom = NULL, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: PLS-LDA (plsgenomics)\"))\n",
    "    print(paste0(\"Data Index: \",custom))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(\n",
    "    model_id, \n",
    "    outlier = \"\", \n",
    "    preprocessing=\"\",\n",
    "    source=\"\", \n",
    "    weight = \"\",\n",
    "    n = \"\",\n",
    "    oob_error = \"\",\n",
    "    accuracy = \"\",\n",
    "    r2 = \"\",\n",
    "    chi2prob = \"\",\n",
    "    logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- \"source,outliers,preprocessing,weight,n,oob,accuracy,r2,chi2prob,model_id\"\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        source,\n",
    "        outlier,\n",
    "        preprocessing,\n",
    "        weight,\n",
    "        n,\n",
    "        oob_error,\n",
    "        accuracy,\n",
    "        r2,\n",
    "        chi2prob,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \",\", model_id)\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_pls_lda <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    test_df, \n",
    "    test_labels,\n",
    "    n = 32,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = targets_to_weights,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    save_path = \"./mle/models/gs/\",\n",
    "    seed = NULL,\n",
    "    log_string = \"\"\n",
    "){\n",
    "\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    x_test <- test_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "        x_test <- preprocess_fn(x_test)\n",
    "    }\n",
    "    # nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample\n",
    "    grid <- expand.grid(\n",
    "        nrounds=1000,\n",
    "        max_depth = c(32, 64),\n",
    "        eta = c(0.05, 0.01),\n",
    "        gamma = c(0.5, 1),\n",
    "        colsample_bytree = c(0.6, 0.8),\n",
    "        min_child_weight = c(1, 2, 4),\n",
    "        subsample = c(0.3, 0.4)\n",
    "    )\n",
    "\n",
    "    if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "        levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "        }\n",
    "        \n",
    "    train_ctrl <- caret::trainControl(\n",
    "        method = \"repeatedcv\",\n",
    "        number = 10,\n",
    "        search = \"random\",\n",
    "        sampling = NULL,\n",
    "        repeats = 1\n",
    "    )\n",
    "    \n",
    "    pls_model <- caret::train(\n",
    "        x_train, \n",
    "        train_labels, \n",
    "        #maxit = 100000,\n",
    "        method=\"xgbTree\",\n",
    "        preProcess = c(\"center\", \"scale\", \"knnImpute\"),\n",
    "        tree_method = \"hist\",\n",
    "        weights = weight_fn(train_labels),\n",
    "        trControl = train_ctrl\n",
    "        #tuneGrid = grid\n",
    "        #tuneLength = n\n",
    "    )\n",
    "\n",
    "    print(pls_model)\n",
    "\n",
    "    save(\n",
    "        pls_model,\n",
    "        file = file.path(save_path, paste0(model_id, \".rda\"))\n",
    "    )\n",
    "\n",
    "    # create predictions (ranger)\n",
    "    model_predictions <- predict(\n",
    "            pls_model, \n",
    "            newdata = x_test\n",
    "        )\n",
    "\n",
    "    print(model_predictions)\n",
    "\n",
    "\n",
    "    # generate the confusion matrix\n",
    "\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        test_labels,\n",
    "        model_predictions %>% as.factor(),\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "    log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            custom = log_string,\n",
    "            distribition = model_predictions %>% as.factor() %>% table(),\n",
    "            logpath = \"./gs_xgb.log\")\n",
    "\n",
    "    return(\n",
    "        list(\n",
    "                model = pls_model,\n",
    "                confusion = confusion_matrix %>% as.list()\n",
    "                )\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "base_paths <- c(\n",
    "    \"img_raw_raw.csv\",\n",
    "    #\"grd_raw_raw.csv\",\n",
    "    \"corrected_and_img.csv\",\n",
    "    #\"grd_corrected_only_bands.csv\",# include veg indices\n",
    "    #\"img_only_bands.csv\",\n",
    "    #\"grd_only_bands.csv\",\n",
    "    #\"corrected_and_img_only_bands.csv\",\n",
    "    \"img_indices_only.csv\"# include veg indices\n",
    "    #\"grd_raw_corrected.csv\",\n",
    "    #\"grd_indices_only.csv\"\n",
    ")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculate_posterior_weights <- function(validation_path =\"figures/merged_validation_s.csv\" ){\n",
    "\n",
    "    validation_df <- read.csv(validation_path, header = TRUE)\n",
    "    #print(head(validation_df))\n",
    "\n",
    "    total_observations <- sum(validation_df$validation_counts)\n",
    "    #print(total_observations)\n",
    "    weights <- (1/ validation_df$validation_prop)\n",
    "    #print(validation_df$validation_prop)\n",
    "\n",
    "    total_by_fg1 <- aggregate(\n",
    "        x = validation_df$validation_counts,\n",
    "        by = list(validation_df$key),\n",
    "        FUN = sum\n",
    "    )\n",
    "\n",
    "    fg1_weight_list <- list()\n",
    "\n",
    "    for( row_idx in seq(nrow(total_by_fg1))){\n",
    "        name <- total_by_fg1$Group.1[[row_idx]]\n",
    "        value <- total_by_fg1$x[[row_idx]]\n",
    "        fg1_weight_list[name] <- value\n",
    "    }\n",
    "    \n",
    "    return(fg1_weight_list)\n",
    "}\n",
    "\n",
    "get_posterior_weights_from_targets <- function(target_factor, posterior_weight = calculate_posterior_weights()){\n",
    "    unbiased_weights <- targets_to_weights(target_factor)\n",
    "\n",
    "    target_name_char <- target_factor %>% as.character()\n",
    "\n",
    "    output_weights <- seq_along(target_factor)\n",
    "\n",
    "    for(i in seq_along(target_factor)){\n",
    "        if(posterior_weight[[target_name_char[[i]]]] > 0){\n",
    "            fg1_weight <- 1 / posterior_weight[[target_name_char[[i]]]]\n",
    "        } else {\n",
    "            fg1_weight <- 0\n",
    "        }\n",
    "        output_weights[[i]] <- unbiased_weights[[i]] * fg1_weight\n",
    "    }\n",
    "\n",
    "    return(output_weights)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "\n",
    "Peter\n",
    "* Increasing number of trees will improve the accuracy/validation mismatch\n",
    "* bias in \n",
    "\n",
    "Ken\n",
    "* decreasing the number of the trees will decrease the impact of the posterior weighting on chi-squared statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "outlier_functions <- list(\n",
    "    #clip = load_model(\"./mle/clip_transform.rda\"),\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)}# no transform\n",
    ")\n",
    "\n",
    "outlier_treatments <- c(\n",
    "    \"no_treatment\",\n",
    "    \"clip\"\n",
    ")\n",
    "\n",
    "preprocess_functions <- list(\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)},# no transform\n",
    "    min_max = columnwise_min_max_scale,\n",
    "    robust = columnwise_robust_scale,\n",
    "    standard = standardize_df\n",
    ")\n",
    "\n",
    "weight_functions <- list(\n",
    "    posterior = get_posterior_weights_from_targets,\n",
    "    balanced = targets_to_weights,\n",
    "    no_treatment = function(x){return(NULL)}# No weights\n",
    ")\n",
    "weight_treatments <- c(\n",
    "    \"balanced\"#,\n",
    "    #\"no_treatment\",\n",
    "    #\"posterior\"\n",
    ")\n",
    "\n",
    "preprocessing_treatments <- c(\n",
    "    \"no_treatment\"#,\n",
    "    #\"standard\",\n",
    "    #\"min_max\",\n",
    "    #\"robust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "num_components <- c(\n",
    "    1,2,4,6,8,10,12,14,16,18,20,24,32,50#,64,75,100,128,200,256,512,1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test_data <- subset(read.csv(\"Data/gs/x_test/img_raw_raw.csv\"), select = -c(X))\n",
    "test_labels <- read.csv(\"Data/gs/y_test/img_raw_raw.csv\")$x %>% as.factor()\n",
    "#train_labels <- read.csv(\"Data/gs/y_train/img_raw_raw.csv\")$x %>% as.factor()\n",
    "manifest_path <- \"./gs_manifest_xgboost_fg0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"no_treatment\"\n",
      "[1] \"Number of columns in train and test:\"\n",
      "[1] 214\n",
      "[1] 214\n",
      "[1] \"Number of rows in train and number of labels:\"\n",
      "[1] 4681\n",
      "[1] 4681\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: The tuning parameter grid should have columns nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample\n",
     "output_type": "error",
     "traceback": [
      "Error: The tuning parameter grid should have columns nrounds, max_depth, eta, gamma, colsample_bytree, min_child_weight, subsample\nTraceback:\n",
      "1. train_pls_lda(train_data, labels, test_data, test_labels, n = n, \n .     outlier_fn = outlier_functions[[o_treatment]], preprocess_fn = preprocess_functions[[p_treatment]], \n .     weight_fn = weight_functions[[w_treatment]], model_id = model_id, \n .     seed = 61718, log_string = paste(n, filepath, o_treatment, \n .         p_treatment, w_treatment))",
      "2. caret::train(x_train, train_labels, method = \"xgbTree\", preProcess = c(\"center\", \n .     \"scale\", \"knnImpute\"), weights = weight_fn(train_labels), \n .     trControl = train_ctrl, tuneGrid = grid)   # at line 54-64 of file <text>",
      "3. train.default(x_train, train_labels, method = \"xgbTree\", preProcess = c(\"center\", \n .     \"scale\", \"knnImpute\"), weights = weight_fn(train_labels), \n .     trControl = train_ctrl, tuneGrid = grid)",
      "4. stop(paste(\"The tuning parameter grid should have columns\", paste(tuneNames, \n .     collapse = \", \", sep = \"\")), call. = FALSE)"
     ]
    }
   ],
   "source": [
    "for(filepath in base_paths){\n",
    "    train_data <- subset(read.csv(paste0(\"Data/gs/x_train/\", filepath)), select = -c(X))\n",
    "    labels <- read.csv(paste0(\"Data/gs/y_train/\", filepath))$x %>% as.factor()\n",
    "\n",
    "                n <- \"NA\"\n",
    "                p_treatment <- \"no_treatment\"\n",
    "                o_treatment <- \"no_treatment\"\n",
    "                w_treatment <- \"no_treatment\"\n",
    "                print(p_treatment)\n",
    "                print(\"Number of columns in train and test:\")\n",
    "                print(ncol(train_data))\n",
    "                print(ncol(test_data))\n",
    "                print(\"Number of rows in train and number of labels:\")\n",
    "                print(nrow(train_data))\n",
    "                print(length(labels))\n",
    "\n",
    "                model_id <- uuid::UUIDgenerate()\n",
    "                save_path <- paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "                if(!dir.exists(save_path)){\n",
    "                    dir.create(save_path)\n",
    "                }\n",
    "\n",
    "                rf_model_results <- train_pls_lda(\n",
    "                    train_data, \n",
    "                    labels, \n",
    "                    test_data,\n",
    "                    test_labels,\n",
    "                    n = n,\n",
    "                    outlier_fn = outlier_functions[[o_treatment]],\n",
    "                    preprocess_fn = preprocess_functions[[p_treatment]],\n",
    "                    weight_fn = weight_functions[[w_treatment]],\n",
    "                    model_id = model_id,\n",
    "                    seed=61718,\n",
    "                    log_string = paste(n, filepath, o_treatment, p_treatment, w_treatment)\n",
    "                )\n",
    "                print(rf_model_results)\n",
    "\n",
    "                rf_model <- rf_model_results$model\n",
    "                acc <- as.list(rf_model_results$confusion$overall)$Accuracy\n",
    "                print(acc)\n",
    "\n",
    "                if(acc > 0.6){\n",
    "\n",
    "                results <- validate_model(\n",
    "                    rf_model, \n",
    "                    save_path, \n",
    "                    outlier_processing = outlier_functions[[o_treatment]],\n",
    "                    transform_type = preprocess_functions[[p_treatment]],\n",
    "                    pft_aggregation=0\n",
    "                )\n",
    "\n",
    "                aggregated_results <- aggregate_results(save_path)\n",
    "\n",
    "                # calculate validation statistics\n",
    "                chi2 <- calculate_chi_squared_probability(aggregated_results)\n",
    "                r2 <- calculate_validation_r2(aggregated_results)\n",
    "                rpd <- calculate_rpd(aggregated_results)\n",
    "\n",
    "\n",
    "                add_model_to_manifest(\n",
    "                    model_id = model_id,\n",
    "                    outlier = o_treatment,\n",
    "                    preprocessing = p_treatment,\n",
    "                    source = filepath,\n",
    "                    weight = w_treatment,\n",
    "                    n = n,\n",
    "                    oob_error = \"NA\",\n",
    "                    accuracy = acc,\n",
    "                    r2 = r2,\n",
    "                    chi2prob = rpd,\n",
    "                    logpath=manifest_path\n",
    "                )\n",
    "\n",
    "                plot_by_pft(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"aggregate.html\"),\n",
    "                    open = FALSE,\n",
    "                    image_path = NULL,\n",
    "                    aggregation=0\n",
    "                )\n",
    "            #\n",
    "                write_validation_table(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"table.html\"),\n",
    "                    open = FALSE\n",
    "                )\n",
    "                } else {\n",
    "                    add_model_to_manifest(\n",
    "                        model_id = model_id,\n",
    "                        outlier = o_treatment,\n",
    "                        preprocessing = p_treatment,\n",
    "                        source = filepath,\n",
    "                        weight = w_treatment,\n",
    "                        n = n,\n",
    "                        oob_error = rf_model$prediction.error,\n",
    "                        accuracy = acc,\n",
    "                        r2 = \"Skipped\",\n",
    "                        chi2prob = \"Skipped\",\n",
    "                        logpath=manifest_path\n",
    "                    )\n",
    "                }\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
