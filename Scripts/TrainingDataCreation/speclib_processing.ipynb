{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LecoSpec Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] '2.0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#source(\"Functions/lecospectR.R\", echo = FALSE)\n",
    "packageVersion(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks use their location as their working directory, so\n",
    "# if we are in a subfolder, move to the main folder.  \n",
    "# This however can safely be run multiple times\n",
    "#setwd(M:/lecospec/lecospec)\n",
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "Throughout the notebook, variables starting with `img_` are UAV image-based information (data, filepaths, etc).  Similarly, variables beginning with `grd_` related to data collected on the ground.  \n",
    "\n",
    "Also, some other naming conventions for variables with data transformations:\n",
    "* `robust` in a variable name refers to data treated by center according to the median and scaling by teh inter-quartile range (a la sklearns RobustScaler)\n",
    "* `minmax` (and its ilk) are min-max scaled data, i.e. scaled to the interval [0,1] by subtracting the minimum and dividing by the range.\n",
    "* `standard(ized)` refers to data treated with with the z-score transform by centring using the mean and scaling y the standard deviation (like sklearns StandardScaler)\n",
    "* `corrected` means that a linear transformation has been applied to account for differences in sensor calibration.\n",
    "* `raw` refers to having no transformations applied\n",
    "* `clipped` means that outliers have been clipped to the upper and lower fence values based on the Inter-Quartile Range method. \n",
    "* `imputed` means that outliers have been removed and imputed\n",
    "* `dropped` means that dataframe rows containing outliers have been removed\n",
    "\n",
    "Example: `img_robust_indices` refers to vegetation indices from the UAV images treated with the robust scaler. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2186</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>ScanID</th><th scope=col>Area</th><th scope=col>Code_name</th><th scope=col>Species_name</th><th scope=col>Functional_group1</th><th scope=col>Functional_group2</th><th scope=col>Species_name_Freq</th><th scope=col>Functional_group1_Freq</th><th scope=col>Functional_group2_Freq</th><th scope=col>⋯</th><th scope=col>Radiometric.Calibration</th><th scope=col>Units</th><th scope=col>Latitude</th><th scope=col>Longitude</th><th scope=col>Altitude</th><th scope=col>GPS.Time</th><th scope=col>Satellites</th><th scope=col>Calibrated.Reference.Correction.File</th><th scope=col>Channels</th><th scope=col>ScanNum</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>aleoch_Murph_061</td><td>Murphy     </td><td>aleoch</td><td>Alectoria ochroleuca</td><td>Lichen    </td><td>LightTerrestrialMacrolichen</td><td> 6</td><td>453</td><td>118</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>aleoch_Murph_063</td><td>Murphy     </td><td>aleoch</td><td>Alectoria ochroleuca</td><td>Lichen    </td><td>LightTerrestrialMacrolichen</td><td> 6</td><td>453</td><td>118</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>aleoch_Murph_064</td><td>Murphy     </td><td>aleoch</td><td>Alectoria ochroleuca</td><td>Lichen    </td><td>LightTerrestrialMacrolichen</td><td> 6</td><td>453</td><td>118</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>aleoch_Murph_065</td><td>Murphy     </td><td>aleoch</td><td>Alectoria ochroleuca</td><td>Lichen    </td><td>LightTerrestrialMacrolichen</td><td> 6</td><td>453</td><td>118</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>aleoch_Murph_066</td><td>Murphy     </td><td>aleoch</td><td>Alectoria ochroleuca</td><td>Lichen    </td><td>LightTerrestrialMacrolichen</td><td> 6</td><td>453</td><td>118</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>alnfru_00003    </td><td>Yukon_Delta</td><td>alnfru</td><td>Alnus sp.           </td><td>ShrubDecid</td><td>ShrubAlder                 </td><td>82</td><td>360</td><td> 82</td><td>⋯</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2186\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & X & ScanID & Area & Code\\_name & Species\\_name & Functional\\_group1 & Functional\\_group2 & Species\\_name\\_Freq & Functional\\_group1\\_Freq & Functional\\_group2\\_Freq & ⋯ & Radiometric.Calibration & Units & Latitude & Longitude & Altitude & GPS.Time & Satellites & Calibrated.Reference.Correction.File & Channels & ScanNum\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <int> & <int> & <int> & ⋯ & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & aleoch\\_Murph\\_061 & Murphy      & aleoch & Alectoria ochroleuca & Lichen     & LightTerrestrialMacrolichen &  6 & 453 & 118 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\t2 & 2 & aleoch\\_Murph\\_063 & Murphy      & aleoch & Alectoria ochroleuca & Lichen     & LightTerrestrialMacrolichen &  6 & 453 & 118 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\t3 & 3 & aleoch\\_Murph\\_064 & Murphy      & aleoch & Alectoria ochroleuca & Lichen     & LightTerrestrialMacrolichen &  6 & 453 & 118 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\t4 & 4 & aleoch\\_Murph\\_065 & Murphy      & aleoch & Alectoria ochroleuca & Lichen     & LightTerrestrialMacrolichen &  6 & 453 & 118 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\t5 & 5 & aleoch\\_Murph\\_066 & Murphy      & aleoch & Alectoria ochroleuca & Lichen     & LightTerrestrialMacrolichen &  6 & 453 & 118 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\t6 & 6 & alnfru\\_00003     & Yukon\\_Delta & alnfru & Alnus sp.            & ShrubDecid & ShrubAlder                  & 82 & 360 &  82 & ⋯ & NA & NA & NA & NA & NA & NA & NA & NA & NA & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2186\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | ScanID &lt;chr&gt; | Area &lt;chr&gt; | Code_name &lt;chr&gt; | Species_name &lt;chr&gt; | Functional_group1 &lt;chr&gt; | Functional_group2 &lt;chr&gt; | Species_name_Freq &lt;int&gt; | Functional_group1_Freq &lt;int&gt; | Functional_group2_Freq &lt;int&gt; | ⋯ ⋯ | Radiometric.Calibration &lt;chr&gt; | Units &lt;chr&gt; | Latitude &lt;dbl&gt; | Longitude &lt;dbl&gt; | Altitude &lt;dbl&gt; | GPS.Time &lt;chr&gt; | Satellites &lt;chr&gt; | Calibrated.Reference.Correction.File &lt;chr&gt; | Channels &lt;int&gt; | ScanNum &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | aleoch_Murph_061 | Murphy      | aleoch | Alectoria ochroleuca | Lichen     | LightTerrestrialMacrolichen |  6 | 453 | 118 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "| 2 | 2 | aleoch_Murph_063 | Murphy      | aleoch | Alectoria ochroleuca | Lichen     | LightTerrestrialMacrolichen |  6 | 453 | 118 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "| 3 | 3 | aleoch_Murph_064 | Murphy      | aleoch | Alectoria ochroleuca | Lichen     | LightTerrestrialMacrolichen |  6 | 453 | 118 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "| 4 | 4 | aleoch_Murph_065 | Murphy      | aleoch | Alectoria ochroleuca | Lichen     | LightTerrestrialMacrolichen |  6 | 453 | 118 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "| 5 | 5 | aleoch_Murph_066 | Murphy      | aleoch | Alectoria ochroleuca | Lichen     | LightTerrestrialMacrolichen |  6 | 453 | 118 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "| 6 | 6 | alnfru_00003     | Yukon_Delta | alnfru | Alnus sp.            | ShrubDecid | ShrubAlder                  | 82 | 360 |  82 | ⋯ | NA | NA | NA | NA | NA | NA | NA | NA | NA | NA |\n",
       "\n"
      ],
      "text/plain": [
       "  X ScanID           Area        Code_name Species_name        \n",
       "1 1 aleoch_Murph_061 Murphy      aleoch    Alectoria ochroleuca\n",
       "2 2 aleoch_Murph_063 Murphy      aleoch    Alectoria ochroleuca\n",
       "3 3 aleoch_Murph_064 Murphy      aleoch    Alectoria ochroleuca\n",
       "4 4 aleoch_Murph_065 Murphy      aleoch    Alectoria ochroleuca\n",
       "5 5 aleoch_Murph_066 Murphy      aleoch    Alectoria ochroleuca\n",
       "6 6 alnfru_00003     Yukon_Delta alnfru    Alnus sp.           \n",
       "  Functional_group1 Functional_group2           Species_name_Freq\n",
       "1 Lichen            LightTerrestrialMacrolichen  6               \n",
       "2 Lichen            LightTerrestrialMacrolichen  6               \n",
       "3 Lichen            LightTerrestrialMacrolichen  6               \n",
       "4 Lichen            LightTerrestrialMacrolichen  6               \n",
       "5 Lichen            LightTerrestrialMacrolichen  6               \n",
       "6 ShrubDecid        ShrubAlder                  82               \n",
       "  Functional_group1_Freq Functional_group2_Freq ⋯ Radiometric.Calibration Units\n",
       "1 453                    118                    ⋯ NA                      NA   \n",
       "2 453                    118                    ⋯ NA                      NA   \n",
       "3 453                    118                    ⋯ NA                      NA   \n",
       "4 453                    118                    ⋯ NA                      NA   \n",
       "5 453                    118                    ⋯ NA                      NA   \n",
       "6 360                     82                    ⋯ NA                      NA   \n",
       "  Latitude Longitude Altitude GPS.Time Satellites\n",
       "1 NA       NA        NA       NA       NA        \n",
       "2 NA       NA        NA       NA       NA        \n",
       "3 NA       NA        NA       NA       NA        \n",
       "4 NA       NA        NA       NA       NA        \n",
       "5 NA       NA        NA       NA       NA        \n",
       "6 NA       NA        NA       NA       NA        \n",
       "  Calibrated.Reference.Correction.File Channels ScanNum\n",
       "1 NA                                   NA       NA     \n",
       "2 NA                                   NA       NA     \n",
       "3 NA                                   NA       NA     \n",
       "4 NA                                   NA       NA     \n",
       "5 NA                                   NA       NA     \n",
       "6 NA                                   NA       NA     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spectral library\n",
    "grd_base_path <- \"./Output/C_001_SC3_Cleaned_SpectralLib.csv\"\n",
    "grd_speclib <- read.csv(grd_base_path, header = TRUE)\n",
    "#grd_index_path <- ./Data/D_002_SpecLib_Derivs.csv\n",
    "#grd_indices <- read.csv(grd_index_path)\n",
    "# this data has some lines that have no labels, so we remove them \n",
    "grd_speclib <- grd_speclib[!is.na(grd_speclib$Functional_group1),]\n",
    "head(grd_speclib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 609</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>UID</th><th scope=col>ScanNum</th><th scope=col>sample_name</th><th scope=col>PFT</th><th scope=col>FncGrp1</th><th scope=col>Site</th><th scope=col>X398</th><th scope=col>X399</th><th scope=col>X400</th><th scope=col>⋯</th><th scope=col>X990</th><th scope=col>X991</th><th scope=col>X992</th><th scope=col>X993</th><th scope=col>X994</th><th scope=col>X995</th><th scope=col>X996</th><th scope=col>X997</th><th scope=col>X998</th><th scope=col>X999</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_1</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.05814769</td><td>0.05926529</td><td>0.06028869</td><td>⋯</td><td>0.6815182</td><td>0.6811660</td><td>0.6890470</td><td>0.7040298</td><td>0.7249807</td><td>0.7507566</td><td>0.7801884</td><td>0.8121027</td><td>0.8453261</td><td>0.8786852</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_2</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.04456014</td><td>0.04778814</td><td>0.05079318</td><td>⋯</td><td>0.6706666</td><td>0.6683159</td><td>0.6786394</td><td>0.7000307</td><td>0.7308801</td><td>0.7695067</td><td>0.8140391</td><td>0.8625739</td><td>0.9132079</td><td>0.9640378</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_3</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.03929324</td><td>0.04265593</td><td>0.04557066</td><td>⋯</td><td>0.5152525</td><td>0.5091915</td><td>0.5178217</td><td>0.5395294</td><td>0.5726982</td><td>0.6156166</td><td>0.6663192</td><td>0.7227978</td><td>0.7830447</td><td>0.8450520</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_4</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.13230228</td><td>0.11122692</td><td>0.09129034</td><td>⋯</td><td>0.5120581</td><td>0.5113880</td><td>0.5348292</td><td>0.5745538</td><td>0.6227243</td><td>0.6723311</td><td>0.7185860</td><td>0.7570701</td><td>0.7833644</td><td>0.7930498</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_5</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.05211388</td><td>0.05565497</td><td>0.05878525</td><td>⋯</td><td>0.6863419</td><td>0.6680365</td><td>0.6509006</td><td>0.6344450</td><td>0.6181806</td><td>0.6017555</td><td>0.5851848</td><td>0.5685449</td><td>0.5519121</td><td>0.5353626</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>BisonGulchPFTsBetula1</td><td>1</td><td>spec_6</td><td>Betula</td><td>TreeBroadleaf</td><td>BisonGulch</td><td>0.06955397</td><td>0.06788242</td><td>0.06631141</td><td>⋯</td><td>0.7354495</td><td>0.7371508</td><td>0.7445194</td><td>0.7567953</td><td>0.7732173</td><td>0.7930235</td><td>0.8154512</td><td>0.8397375</td><td>0.8651196</td><td>0.8908347</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 609\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & X & UID & ScanNum & sample\\_name & PFT & FncGrp1 & Site & X398 & X399 & X400 & ⋯ & X990 & X991 & X992 & X993 & X994 & X995 & X996 & X997 & X998 & X999\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & BisonGulchPFTsBetula1 & 1 & spec\\_1 & Betula & TreeBroadleaf & BisonGulch & 0.05814769 & 0.05926529 & 0.06028869 & ⋯ & 0.6815182 & 0.6811660 & 0.6890470 & 0.7040298 & 0.7249807 & 0.7507566 & 0.7801884 & 0.8121027 & 0.8453261 & 0.8786852\\\\\n",
       "\t2 & 2 & BisonGulchPFTsBetula1 & 1 & spec\\_2 & Betula & TreeBroadleaf & BisonGulch & 0.04456014 & 0.04778814 & 0.05079318 & ⋯ & 0.6706666 & 0.6683159 & 0.6786394 & 0.7000307 & 0.7308801 & 0.7695067 & 0.8140391 & 0.8625739 & 0.9132079 & 0.9640378\\\\\n",
       "\t3 & 3 & BisonGulchPFTsBetula1 & 1 & spec\\_3 & Betula & TreeBroadleaf & BisonGulch & 0.03929324 & 0.04265593 & 0.04557066 & ⋯ & 0.5152525 & 0.5091915 & 0.5178217 & 0.5395294 & 0.5726982 & 0.6156166 & 0.6663192 & 0.7227978 & 0.7830447 & 0.8450520\\\\\n",
       "\t4 & 4 & BisonGulchPFTsBetula1 & 1 & spec\\_4 & Betula & TreeBroadleaf & BisonGulch & 0.13230228 & 0.11122692 & 0.09129034 & ⋯ & 0.5120581 & 0.5113880 & 0.5348292 & 0.5745538 & 0.6227243 & 0.6723311 & 0.7185860 & 0.7570701 & 0.7833644 & 0.7930498\\\\\n",
       "\t5 & 5 & BisonGulchPFTsBetula1 & 1 & spec\\_5 & Betula & TreeBroadleaf & BisonGulch & 0.05211388 & 0.05565497 & 0.05878525 & ⋯ & 0.6863419 & 0.6680365 & 0.6509006 & 0.6344450 & 0.6181806 & 0.6017555 & 0.5851848 & 0.5685449 & 0.5519121 & 0.5353626\\\\\n",
       "\t6 & 6 & BisonGulchPFTsBetula1 & 1 & spec\\_6 & Betula & TreeBroadleaf & BisonGulch & 0.06955397 & 0.06788242 & 0.06631141 & ⋯ & 0.7354495 & 0.7371508 & 0.7445194 & 0.7567953 & 0.7732173 & 0.7930235 & 0.8154512 & 0.8397375 & 0.8651196 & 0.8908347\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 609\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | UID &lt;chr&gt; | ScanNum &lt;chr&gt; | sample_name &lt;chr&gt; | PFT &lt;chr&gt; | FncGrp1 &lt;chr&gt; | Site &lt;chr&gt; | X398 &lt;dbl&gt; | X399 &lt;dbl&gt; | X400 &lt;dbl&gt; | ⋯ ⋯ | X990 &lt;dbl&gt; | X991 &lt;dbl&gt; | X992 &lt;dbl&gt; | X993 &lt;dbl&gt; | X994 &lt;dbl&gt; | X995 &lt;dbl&gt; | X996 &lt;dbl&gt; | X997 &lt;dbl&gt; | X998 &lt;dbl&gt; | X999 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | BisonGulchPFTsBetula1 | 1 | spec_1 | Betula | TreeBroadleaf | BisonGulch | 0.05814769 | 0.05926529 | 0.06028869 | ⋯ | 0.6815182 | 0.6811660 | 0.6890470 | 0.7040298 | 0.7249807 | 0.7507566 | 0.7801884 | 0.8121027 | 0.8453261 | 0.8786852 |\n",
       "| 2 | 2 | BisonGulchPFTsBetula1 | 1 | spec_2 | Betula | TreeBroadleaf | BisonGulch | 0.04456014 | 0.04778814 | 0.05079318 | ⋯ | 0.6706666 | 0.6683159 | 0.6786394 | 0.7000307 | 0.7308801 | 0.7695067 | 0.8140391 | 0.8625739 | 0.9132079 | 0.9640378 |\n",
       "| 3 | 3 | BisonGulchPFTsBetula1 | 1 | spec_3 | Betula | TreeBroadleaf | BisonGulch | 0.03929324 | 0.04265593 | 0.04557066 | ⋯ | 0.5152525 | 0.5091915 | 0.5178217 | 0.5395294 | 0.5726982 | 0.6156166 | 0.6663192 | 0.7227978 | 0.7830447 | 0.8450520 |\n",
       "| 4 | 4 | BisonGulchPFTsBetula1 | 1 | spec_4 | Betula | TreeBroadleaf | BisonGulch | 0.13230228 | 0.11122692 | 0.09129034 | ⋯ | 0.5120581 | 0.5113880 | 0.5348292 | 0.5745538 | 0.6227243 | 0.6723311 | 0.7185860 | 0.7570701 | 0.7833644 | 0.7930498 |\n",
       "| 5 | 5 | BisonGulchPFTsBetula1 | 1 | spec_5 | Betula | TreeBroadleaf | BisonGulch | 0.05211388 | 0.05565497 | 0.05878525 | ⋯ | 0.6863419 | 0.6680365 | 0.6509006 | 0.6344450 | 0.6181806 | 0.6017555 | 0.5851848 | 0.5685449 | 0.5519121 | 0.5353626 |\n",
       "| 6 | 6 | BisonGulchPFTsBetula1 | 1 | spec_6 | Betula | TreeBroadleaf | BisonGulch | 0.06955397 | 0.06788242 | 0.06631141 | ⋯ | 0.7354495 | 0.7371508 | 0.7445194 | 0.7567953 | 0.7732173 | 0.7930235 | 0.8154512 | 0.8397375 | 0.8651196 | 0.8908347 |\n",
       "\n"
      ],
      "text/plain": [
       "  X UID                   ScanNum sample_name PFT    FncGrp1       Site      \n",
       "1 1 BisonGulchPFTsBetula1 1       spec_1      Betula TreeBroadleaf BisonGulch\n",
       "2 2 BisonGulchPFTsBetula1 1       spec_2      Betula TreeBroadleaf BisonGulch\n",
       "3 3 BisonGulchPFTsBetula1 1       spec_3      Betula TreeBroadleaf BisonGulch\n",
       "4 4 BisonGulchPFTsBetula1 1       spec_4      Betula TreeBroadleaf BisonGulch\n",
       "5 5 BisonGulchPFTsBetula1 1       spec_5      Betula TreeBroadleaf BisonGulch\n",
       "6 6 BisonGulchPFTsBetula1 1       spec_6      Betula TreeBroadleaf BisonGulch\n",
       "  X398       X399       X400       ⋯ X990      X991      X992      X993     \n",
       "1 0.05814769 0.05926529 0.06028869 ⋯ 0.6815182 0.6811660 0.6890470 0.7040298\n",
       "2 0.04456014 0.04778814 0.05079318 ⋯ 0.6706666 0.6683159 0.6786394 0.7000307\n",
       "3 0.03929324 0.04265593 0.04557066 ⋯ 0.5152525 0.5091915 0.5178217 0.5395294\n",
       "4 0.13230228 0.11122692 0.09129034 ⋯ 0.5120581 0.5113880 0.5348292 0.5745538\n",
       "5 0.05211388 0.05565497 0.05878525 ⋯ 0.6863419 0.6680365 0.6509006 0.6344450\n",
       "6 0.06955397 0.06788242 0.06631141 ⋯ 0.7354495 0.7371508 0.7445194 0.7567953\n",
       "  X994      X995      X996      X997      X998      X999     \n",
       "1 0.7249807 0.7507566 0.7801884 0.8121027 0.8453261 0.8786852\n",
       "2 0.7308801 0.7695067 0.8140391 0.8625739 0.9132079 0.9640378\n",
       "3 0.5726982 0.6156166 0.6663192 0.7227978 0.7830447 0.8450520\n",
       "4 0.6227243 0.6723311 0.7185860 0.7570701 0.7833644 0.7930498\n",
       "5 0.6181806 0.6017555 0.5851848 0.5685449 0.5519121 0.5353626\n",
       "6 0.7732173 0.7930235 0.8154512 0.8397375 0.8651196 0.8908347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_base_path <- \"Data/Ground_Validation/PFT_image_spectra/PFT_Image_SpectralLib_Clean.csv\"\n",
    "img_speclib <- read.csv(img_base_path)\n",
    "\n",
    "# currently, not using the old pre-proccessing scheme and just doing it here.\n",
    "#img_index_path <- Data/D_002_Image_SpecLib_Derivs.csv\n",
    "#img_speclib <- read.csv(img_base_path)\n",
    "head(img_speclib)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, there are some metadata columns that should not be there for the next step - lets remove them with `subset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Site\n",
      "c..BisonGulch....sBetula1..     BisonGulch\n",
      "c..Chatanika....sBetula_nana1..  Chatanika\n",
      "c..EightMile....sBetula_nana1..  EightMile\n",
      "c..Bonanza....sLarix1..            Bonanza\n"
     ]
    }
   ],
   "source": [
    "RawUID<- img_speclib %>% \n",
    "  dplyr::select(UID) %>% as.data.frame() #%>%\n",
    "\n",
    "SiteNames<-str_split(RawUID[,1], \"PFT\") %>% \n",
    "  as.data.frame() %>% \n",
    "  t %>% \n",
    "  as.data.frame() %>%\n",
    "  dplyr::rename(Site = V1) %>% \n",
    "  dplyr::select(Site)\n",
    "print(unique(SiteNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_speclib <- img_speclib[img_speclib$Site == \"BisonGulch\",]\n",
    "ch_speclib <- img_speclib[img_speclib$Site == \"Chatanika\",]\n",
    "em_speclib <- img_speclib[img_speclib$Site == \"EightMile\",]\n",
    "bz_speclib <- img_speclib[img_speclib$Site == \"Bonanza\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'TreeConifer'</li><li>'Moss'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'TreeConifer'\n",
       "\\item 'Moss'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'TreeConifer'\n",
       "2. 'Moss'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"TreeConifer\" \"Moss\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'TreeBroadleaf'</li><li>'ShrubEvergreen'</li><li>'Abiotic'</li><li>'Lichen'</li><li>'TreeConifer'</li><li>'ShrubDecid'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'TreeBroadleaf'\n",
       "\\item 'ShrubEvergreen'\n",
       "\\item 'Abiotic'\n",
       "\\item 'Lichen'\n",
       "\\item 'TreeConifer'\n",
       "\\item 'ShrubDecid'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'TreeBroadleaf'\n",
       "2. 'ShrubEvergreen'\n",
       "3. 'Abiotic'\n",
       "4. 'Lichen'\n",
       "5. 'TreeConifer'\n",
       "6. 'ShrubDecid'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"TreeBroadleaf\"  \"ShrubEvergreen\" \"Abiotic\"        \"Lichen\"        \n",
       "[5] \"TreeConifer\"    \"ShrubDecid\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'ShrubDecid'</li><li>'ShrubEvergreen'</li><li>'Lichen'</li><li>'Graminoid'</li><li>'Abiotic'</li><li>'Moss'</li><li>'TreeConifer'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ShrubDecid'\n",
       "\\item 'ShrubEvergreen'\n",
       "\\item 'Lichen'\n",
       "\\item 'Graminoid'\n",
       "\\item 'Abiotic'\n",
       "\\item 'Moss'\n",
       "\\item 'TreeConifer'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ShrubDecid'\n",
       "2. 'ShrubEvergreen'\n",
       "3. 'Lichen'\n",
       "4. 'Graminoid'\n",
       "5. 'Abiotic'\n",
       "6. 'Moss'\n",
       "7. 'TreeConifer'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ShrubDecid\"     \"ShrubEvergreen\" \"Lichen\"         \"Graminoid\"     \n",
       "[5] \"Abiotic\"        \"Moss\"           \"TreeConifer\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'ShrubDecid'</li><li>'TreeBroadleaf'</li><li>'Graminoid'</li><li>'Abiotic'</li><li>'ShrubEvergreen'</li><li>'TreeConifer'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ShrubDecid'\n",
       "\\item 'TreeBroadleaf'\n",
       "\\item 'Graminoid'\n",
       "\\item 'Abiotic'\n",
       "\\item 'ShrubEvergreen'\n",
       "\\item 'TreeConifer'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ShrubDecid'\n",
       "2. 'TreeBroadleaf'\n",
       "3. 'Graminoid'\n",
       "4. 'Abiotic'\n",
       "5. 'ShrubEvergreen'\n",
       "6. 'TreeConifer'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ShrubDecid\"     \"TreeBroadleaf\"  \"Graminoid\"      \"Abiotic\"       \n",
       "[5] \"ShrubEvergreen\" \"TreeConifer\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(bz_speclib$FncGrp1)\n",
    "unique(bg_speclib$FncGrp1)\n",
    "unique(em_speclib$FncGrp1)\n",
    "unique(ch_speclib$FncGrp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_bands <- subset(\n",
    "    img_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))\n",
    "\n",
    "\n",
    "grd_bands <- subset(\n",
    "    grd_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "        ScanID,\n",
    "        Area,\n",
    "        Code_name,\n",
    "        Species_name,\n",
    "        Functional_group1,\n",
    "        Functional_group2,\n",
    "        Species_name_Freq,\n",
    "        Functional_group1_Freq,\n",
    "        Functional_group2_Freq,\n",
    "        Genus,\n",
    "        Version,\n",
    "        File.Name,\n",
    "        Instrument,\n",
    "        Detectors,\n",
    "        Measurement,\n",
    "        Date,\n",
    "        Time,\n",
    "        Battery.Voltage,\n",
    "        Averages,\n",
    "        Integration1,\n",
    "        Integration2,\n",
    "        Integration3,\n",
    "        Dark.Mode,\n",
    "        Foreoptic,\n",
    "        Radiometric.Calibration,\n",
    "        Units,\n",
    "        Latitude,\n",
    "        Longitude,\n",
    "        Altitude,\n",
    "        GPS.Time,\n",
    "        Satellites,\n",
    "        Calibrated.Reference.Correction.File,\n",
    "        Channels,\n",
    "        ScanNum\n",
    "    )\n",
    ")\n",
    "\n",
    "bg_bands <- subset(\n",
    "    bg_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))\n",
    "\n",
    "\n",
    "em_bands <- subset(\n",
    "    em_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))\n",
    "    \n",
    "bz_bands <- subset(\n",
    "    bz_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))\n",
    "    \n",
    "ch_bands <- subset(\n",
    "    ch_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_bands <- subset(\n",
    "    bg_speclib, \n",
    "    select=-c(\n",
    "        X,\n",
    "    \tUID,\n",
    "        ScanNum,\n",
    "    \tsample_name,\n",
    "    \tPFT,\n",
    "    \tFncGrp1,\n",
    "        Site\n",
    "    ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the vegetation indices from the spectral libraries - its easy with lecospectR!\n",
    "\n",
    "Note that the image-based scpectra are normalized from zero to one, and the ground specctra are on the range zero to one hundred.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_indices <- get_vegetation_indices(img_bands, NULL)# should have a default of NULL, you know?\n",
    "grd_indices <- get_vegetation_indices(grd_bands, NULL)\n",
    "bg_indices <- get_vegetation_indices(bg_speclib, NULL)\n",
    "ch_indices <- get_vegetation_indices(ch_speclib, NULL)\n",
    "bz_indices <- get_vegetation_indices(bz_speclib, NULL)\n",
    "em_indices <- get_vegetation_indices(em_speclib, NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_indices, file=\"Data/gs/x_train/img_indices_only.csv\")\n",
    "\n",
    "write.csv(grd_indices, file=\"Data/gs/x_train/grd_indices_only.csv\")\n",
    "\n",
    "write.csv(bg_indices, file = \"Data/gs/x_train/bison_gulch_indices\")\n",
    "\n",
    "write.csv(ch_indices, file = \"Data/gs/x_train/chatanika_indices.csv\")\n",
    "\n",
    "write.csv(em_indices, file = \"Data/gs/x_train/eight_mile_indices.csv\")\n",
    "\n",
    "write.csv(bz_indices, file = \"Data/gs/x_train/bonanza_indices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(img_indices)\n",
    "head(img_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually enough to start training models.  We have the vegetation indices, but instead of doing that, let's transform the data and write it to file.  Then we will proceed to creating the model corrections, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_resampled_bands <- resample_df(img_bands, drop_existing=TRUE)# corrects scale difference (poorly)\n",
    "grd_resampled_bands <- resample_df(0.01*grd_bands, drop_existing=TRUE)\n",
    "bg_resampled_bands <- resample_df(bg_bands, drop_existing=TRUE)# corrects scale difference (poorly)\n",
    "ch_resampled_bands <- resample_df(ch_bands, drop_existing=TRUE)# corrects scale difference (poorly)\n",
    "bz_resampled_bands <- resample_df(bz_bands, drop_existing=TRUE)# corrects scale difference (poorly)\n",
    "em_resampled_bands <- resample_df(em_bands, drop_existing=TRUE)# corrects scale difference (poorly)\n",
    "\n",
    "head(img_resampled_bands)\n",
    "head(grd_resampled_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_raw_with_na <- cbind(img_resampled_bands, img_indices)\n",
    "grd_raw_with_na <- cbind(grd_resampled_bands, grd_indices)\n",
    "bg_raw_with_na <- cbind(bg_resampled_bands, bg_indices)\n",
    "ch_raw_with_na <- cbind(ch_resampled_bands, ch_indices)\n",
    "em_raw_with_na <- cbind(em_resampled_bands, em_indices)\n",
    "bz_raw_with_na <- cbind(bz_resampled_bands, bz_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_raw <- impute_spectra(img_raw_with_na)\n",
    "grd_raw <- impute_spectra(inf_to_na(grd_raw_with_na))# note also dropping an Inf (liekly div by 0 in veg index)\n",
    "bg_raw <- impute_spectra(bg_raw_with_na)\n",
    "bz_raw <- impute_spectra(bz_raw_with_na)\n",
    "em_raw <- impute_spectra(em_raw_with_na)\n",
    "ch_raw <- impute_spectra(ch_raw_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(bg_raw, file=\"Data/gs/x_train/bison_gulch.csv\")\n",
    "write.csv(as.data.frame(bg_speclib$FncGrp1), file=\"Data/gs/y_train/bison_gulch.csv\")\n",
    "write.csv(bz_raw, file=\"Data/gs/x_train/bonanza.csv\")\n",
    "write.csv(as.data.frame(bz_speclib$FncGrp1), file=\"Data/gs/y_train/bonanza.csv\")\n",
    "write.csv(ch_raw, file=\"Data/gs/x_train/chatanika.csv\")\n",
    "write.csv(as.data.frame(ch_speclib$FncGrp1), file=\"Data/gs/y_train/chatanika.csv\")\n",
    "write.csv(em_raw, file=\"Data/gs/x_train/eight_mile.csv\")\n",
    "write.csv(as.data.frame(em_speclib$FncGrp1), file=\"Data/gs/y_train/eight_mile.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the outlier transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_clipped <- clip_outliers(grd_raw)\n",
    "grd_imputed <- impute_outliers_and_na(grd_raw)\n",
    "grd_dropped <- grd_raw[detect_outliers_columnwise(grd_raw),]\n",
    "img_clipped <- clip_outliers(img_raw)\n",
    "img_imputed <- impute_outliers_and_na(img_raw)\n",
    "img_dropped <- img_raw[detect_outliers_columnwise(img_raw),]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the center/scale transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_raw_robust <- columnwise_robust_scale(grd_raw)\n",
    "img_raw_robust <- columnwise_robust_scale(img_raw)\n",
    "grd_raw_minmax <- columnwise_min_max_scale(grd_raw)\n",
    "img_raw_minmax <- columnwise_min_max_scale(img_raw)\n",
    "grd_raw_standard <- standardize_df(grd_raw)\n",
    "img_raw_standard <- standardize_df(img_raw)\n",
    "\n",
    "grd_clipped_robust <- columnwise_robust_scale(grd_clipped)\n",
    "grd_imputed_robust <- columnwise_robust_scale(grd_imputed)\n",
    "grd_dropped_robust <- columnwise_robust_scale(grd_dropped)\n",
    "img_clipped_robust <- columnwise_robust_scale(img_clipped)\n",
    "img_imputed_robust <- columnwise_robust_scale(img_imputed)\n",
    "img_dropped_robust <- columnwise_robust_scale(img_dropped)\n",
    "\n",
    "grd_clipped_minmax <- columnwise_min_max_scale(grd_clipped)\n",
    "grd_imputed_minmax <- columnwise_min_max_scale(grd_imputed)\n",
    "grd_dropped_minmax <- columnwise_min_max_scale(grd_dropped)\n",
    "img_clipped_minmax <- columnwise_min_max_scale(img_clipped)\n",
    "img_imputed_minmax <- columnwise_min_max_scale(img_imputed)\n",
    "img_dropped_minmax <- columnwise_min_max_scale(img_dropped)\n",
    "\n",
    "grd_clipped_standard <- standardize_df(grd_clipped)\n",
    "grd_imputed_standard <- standardize_df(grd_imputed)\n",
    "grd_dropped_standard <- standardize_df(grd_imputed)\n",
    "img_clipped_standard <- standardize_df(img_clipped)\n",
    "img_imputed_standard <- standardize_df(img_imputed)\n",
    "img_dropped_standard <- standardize_df(img_dropped)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's save all these data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH <- \"Data/gs/\"\n",
    "X_TRAIN_PATH <- paste0(BASE_PATH, \"x_train/\")\n",
    "Y_TRAIN_PATH <- paste0(BASE_PATH, \"y_train/\")\n",
    "\n",
    "X_TEST_PATH <- paste0(BASE_PATH, \"x_test/\")\n",
    "Y_TEST_PATH <- paste0(BASE_PATH, \"y_test/\")\n",
    "\n",
    "if(!dir.exists(BASE_PATH)){\n",
    "    dir.create(BASE_PATH)\n",
    "}\n",
    "if(!dir.exists(X_TRAIN_PATH)){\n",
    "    dir.create(X_TRAIN_PATH)\n",
    "}\n",
    "if(!dir.exists(Y_TRAIN_PATH)){\n",
    "    dir.create(Y_TRAIN_PATH)\n",
    "}\n",
    "if(!dir.exists(X_TEST_PATH)){\n",
    "    dir.create(X_TEST_PATH)\n",
    "}\n",
    "if(!dir.exists(Y_TEST_PATH)){\n",
    "    dir.create(Y_TEST_PATH)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(grd_clipped, file=paste0(X_TRAIN_PATH, \"grd_clipped_raw.csv\"))\n",
    "write.csv(grd_clipped_minmax, file=paste0(X_TRAIN_PATH, \"grd_clipped_minmax.csv\"))\n",
    "write.csv(grd_clipped_robust, file=paste0(X_TRAIN_PATH, \"grd_clipped_robust.csv\"))\n",
    "write.csv(grd_clipped_standard, file=paste0(X_TRAIN_PATH, \"grd_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(grd_imputed, file=paste0(X_TRAIN_PATH, \"grd_imputed_raw.csv\"))\n",
    "write.csv(grd_imputed_minmax, file=paste0(X_TRAIN_PATH, \"grd_imputed_minmax.csv\"))\n",
    "write.csv(grd_imputed_robust, file=paste0(X_TRAIN_PATH, \"grd_imputed_robust.csv\"))\n",
    "write.csv(grd_imputed_standard, file=paste0(X_TRAIN_PATH, \"grd_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(grd_dropped, file=paste0(X_TRAIN_PATH, \"grd_dropped_raw.csv\"))\n",
    "write.csv(grd_dropped_minmax, file=paste0(X_TRAIN_PATH, \"grd_dropped_minmax.csv\"))\n",
    "write.csv(grd_dropped_robust, file=paste0(X_TRAIN_PATH, \"grd_dropped_robust.csv\"))\n",
    "write.csv(grd_dropped_standard, file=paste0(X_TRAIN_PATH, \"grd_dropped_standard.csv\"))\n",
    "\n",
    "write.csv(grd_raw, file=paste0(X_TRAIN_PATH, \"grd_raw_raw.csv\"))\n",
    "write.csv(grd_raw_minmax, file=paste0(X_TRAIN_PATH, \"grd_raw_minmax.csv\"))\n",
    "write.csv(grd_raw_robust, file=paste0(X_TRAIN_PATH, \"grd_raw_robust.csv\"))\n",
    "write.csv(grd_raw_standard, file=paste0(X_TRAIN_PATH, \"grd_raw_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(grd_raw[,colnames(grd_indices)], file=paste0(X_TRAIN_PATH, \"grd_indices_only.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for the above Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_targets <- img_speclib$FncGrp1 %>% as.factor()\n",
    "grd_targets <- grd_speclib$Functional_group1 %>% as.factor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_targets, file=\"Data/gs/y_train/img_indices_only.csv\")\n",
    "write.csv(grd_targets, file=\"Data/gs/y_train/grd_indices_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_targets %>% table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_targets %>% table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# drop entries with outliers to match training data\n",
    "img_targets_dropped <- img_targets[detect_outliers_columnwise(img_raw)]\n",
    "grd_targets_dropped <- grd_targets[detect_outliers_columnwise(grd_raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_clipped_raw.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_clipped_minmax.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_clipped_robust.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_imputed_raw.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_imputed_minmax.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_imputed_robust.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_raw_raw.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_raw_minmax.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_raw_robust.csv\"))\n",
    "write.csv(grd_targets, file=paste0(Y_TRAIN_PATH, \"grd_raw_standard.csv\"))\n",
    "\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TRAIN_PATH, \"grd_dropped_raw.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TRAIN_PATH, \"grd_dropped_minmax.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TRAIN_PATH, \"grd_dropped_robust.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TRAIN_PATH, \"grd_dropped_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_clipped_raw.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_clipped_minmax.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_clipped_robust.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_imputed, file=paste0(Y_TRAIN_PATH, \"img_imputed_raw.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_imputed_minmax.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_imputed_robust.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_raw_raw.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_raw_minmax.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_raw_robust.csv\"))\n",
    "write.csv(img_targets, file=paste0(Y_TRAIN_PATH, \"img_raw_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_dropped, file=paste0(Y_TRAIN_PATH, \"img_dropped_raw.csv\"))\n",
    "write.csv(img_targets_dropped, file=paste0(Y_TRAIN_PATH, \"img_dropped_minmax.csv\"))\n",
    "write.csv(img_targets_dropped, file=paste0(Y_TRAIN_PATH, \"img_dropped_robust.csv\"))\n",
    "write.csv(img_targets_dropped, file=paste0(Y_TRAIN_PATH, \"img_dropped_standard.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "Build the test data, and save it with the same names as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(61718L)\n",
    "\n",
    "permutation <-  permute::shuffle(length(img_targets))\n",
    "sample <- create_stratified_sample(\n",
    "    img_targets, \n",
    "    permutation = permutation,\n",
    "    samples_per_pft = 15)\n",
    "# split the data based on the above sample\n",
    "img_targets_test <- img_targets[permutation][sample]\n",
    "img_targets_train <- img_targets[permutation][-sample]\n",
    "img_raw_test <- img_raw[permutation,][sample,]\n",
    "img_raw_train <- img_raw[permutation,][-sample,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_targets_test %>% as.factor() %>% table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# create the subsampled data and save them for each processing type/treatment\n",
    "\n",
    "# clipped\n",
    "img_clipped_train <- img_clipped[permutation,][-sample,]\n",
    "img_clipped_test <- img_clipped[permutation,][sample,]\n",
    "img_clipped_minmax_train <- img_clipped_minmax[permutation,][-sample,]\n",
    "img_clipped_minmax_test <- img_clipped_minmax[permutation,][sample,]\n",
    "img_clipped_robust_train <- img_clipped_robust[permutation,][-sample,]\n",
    "img_clipped_robust_test <- img_clipped_robust[permutation,][sample,]\n",
    "img_clipped_standard_train <- img_clipped_standard[permutation,][-sample]\n",
    "img_clipped_standard_test <- img_clipped_standard[permutation,][sample,]\n",
    "\n",
    "# raw (note one is done in the previous cell)\n",
    "img_raw_minmax_train <- img_raw_minmax[permutation,][-sample,]\n",
    "img_raw_minmax_test <- img_raw_minmax[permutation,][sample,]\n",
    "img_raw_robust_train <- img_raw_robust[permutation,][-sample,]\n",
    "img_raw_robust_test <- img_raw_robust[permutation,][sample,]\n",
    "img_raw_standard_train <- img_raw_standard[permutation,][sample,]\n",
    "img_raw_standard_test <- img_raw_standard[permutation,][sample,]\n",
    "\n",
    "#imputed\n",
    "img_imputed_train <- img_imputed[permutation,][-sample,]\n",
    "img_imputed_test <- img_imputed[permutation,][sample,]\n",
    "img_imputed_minmax_train <- img_imputed_minmax[permutation,][-sample,]\n",
    "img_imputed_minmax_test <- img_imputed_minmax[permutation,][sample,]\n",
    "img_imputed_robust_train <- img_imputed_robust[permutation,][-sample,]\n",
    "img_imputed_robust_test <- img_imputed_robust[permutation,][sample,]\n",
    "img_imputed_standard_train <- img_imputed_standard[permutation,][-sample,]\n",
    "img_imputed_standard_test <- img_imputed_standard[permutation,][sample,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(length(img_targets_test))\n",
    "print(nrow(img_clipped_robust_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-based Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_clipped_train, file=paste0(X_TRAIN_PATH, \"img_clipped_raw.csv\"))\n",
    "write.csv(img_clipped_minmax_train, file=paste0(X_TRAIN_PATH, \"img_clipped_minmax.csv\"))\n",
    "write.csv(img_clipped_robust_train, file=paste0(X_TRAIN_PATH, \"img_clipped_robust.csv\"))\n",
    "write.csv(img_clipped_standard_train, file=paste0(X_TRAIN_PATH, \"img_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_imputed_train, file=paste0(X_TRAIN_PATH, \"img_imputed_raw.csv\"))\n",
    "write.csv(img_imputed_minmax_train, file=paste0(X_TRAIN_PATH, \"img_imputed_minmax.csv\"))\n",
    "write.csv(img_imputed_robust_train, file=paste0(X_TRAIN_PATH, \"img_imputed_robust.csv\"))\n",
    "write.csv(img_imputed_standard_train, file=paste0(X_TRAIN_PATH, \"img_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_dropped, file=paste0(X_TRAIN_PATH, \"img_dropped_raw.csv\"))\n",
    "write.csv(img_dropped_minmax, file=paste0(X_TRAIN_PATH, \"img_dropped_minmax.csv\"))\n",
    "write.csv(img_dropped_robust, file=paste0(X_TRAIN_PATH, \"img_dropped_robust.csv\"))\n",
    "write.csv(img_dropped_standard, file=paste0(X_TRAIN_PATH, \"img_dropped_standard.csv\"))\n",
    "\n",
    "write.csv(img_raw_train, file=paste0(X_TRAIN_PATH, \"img_raw_raw.csv\"))\n",
    "write.csv(img_raw_minmax_train, file=paste0(X_TRAIN_PATH, \"img_raw_minmax.csv\"))\n",
    "write.csv(img_raw_robust_train, file=paste0(X_TRAIN_PATH, \"img_raw_robust.csv\"))\n",
    "write.csv(img_raw_standard_train, file=paste0(X_TRAIN_PATH, \"img_raw_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_clipped_raw.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_clipped_minmax.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_clipped_robust.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_imputed_raw.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_imputed_minmax.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_imputed_robust.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_imputed_standard.csv\"))\n",
    "\n",
    "#write.csv(img_dropped, file=paste0(X_TRAIN_PATH, \"img_dropped_raw.csv\"))\n",
    "#write.csv(img_dropped_minmax, file=paste0(X_TRAIN_PATH, \"img_dropped_minmax.csv\"))\n",
    "#write.csv(img_dropped_robust, file=paste0(X_TRAIN_PATH, \"img_dropped_robust.csv\"))\n",
    "#write.csv(img_dropped_standard, file=paste0(X_TRAIN_PATH, \"img_dropped_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_raw_raw.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_raw_minmax.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_raw_robust.csv\"))\n",
    "write.csv(img_targets_train, file=paste0(Y_TRAIN_PATH, \"img_raw_standard.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Based Test Data\n",
    "Note: this image-based test set is used for all the models (ground included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_clipped_test, file=paste0(X_TEST_PATH, \"img_clipped_raw.csv\"))\n",
    "write.csv(img_clipped_minmax_test, file=paste0(X_TEST_PATH, \"img_clipped_minmax.csv\"))\n",
    "write.csv(img_clipped_robust_test, file=paste0(X_TEST_PATH, \"img_clipped_robust.csv\"))\n",
    "write.csv(img_clipped_standard_test, file=paste0(X_TEST_PATH, \"img_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_imputed_test, file=paste0(X_TEST_PATH, \"img_imputed_raw.csv\"))\n",
    "write.csv(img_imputed_minmax_test, file=paste0(X_TEST_PATH, \"img_imputed_minmax.csv\"))\n",
    "write.csv(img_imputed_robust_test, file=paste0(X_TEST_PATH, \"img_imputed_robust.csv\"))\n",
    "write.csv(img_imputed_standard_test, file=paste0(X_TEST_PATH, \"img_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_dropped, file=paste0(X_TEST_PATH, \"img_dropped_raw.csv\"))\n",
    "write.csv(img_dropped_minmax, file=paste0(X_TEST_PATH, \"img_dropped_minmax.csv\"))\n",
    "write.csv(img_dropped_robust, file=paste0(X_TEST_PATH, \"img_dropped_robust.csv\"))\n",
    "write.csv(img_dropped_standard, file=paste0(X_TEST_PATH, \"img_dropped_standard.csv\"))\n",
    "\n",
    "write.csv(img_raw_test, file=paste0(X_TEST_PATH, \"img_raw_raw.csv\"))\n",
    "write.csv(img_raw_minmax_test, file=paste0(X_TEST_PATH, \"img_raw_minmax.csv\"))\n",
    "write.csv(img_raw_robust_test, file=paste0(X_TEST_PATH, \"img_raw_robust.csv\"))\n",
    "write.csv(img_raw_standard_test, file=paste0(X_TEST_PATH, \"img_raw_standard.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground test (from the images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_clipped_test, file=paste0(X_TEST_PATH, \"grd_clipped_raw.csv\"))\n",
    "write.csv(img_clipped_minmax_test, file=paste0(X_TEST_PATH, \"grd_clipped_minmax.csv\"))\n",
    "write.csv(img_clipped_robust_test, file=paste0(X_TEST_PATH, \"grd_clipped_robust.csv\"))\n",
    "write.csv(img_clipped_standard_test, file=paste0(X_TEST_PATH, \"grd_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_imputed_test, file=paste0(X_TEST_PATH, \"grd_imputed_raw.csv\"))\n",
    "write.csv(img_imputed_minmax_test, file=paste0(X_TEST_PATH, \"grd_imputed_minmax.csv\"))\n",
    "write.csv(img_imputed_robust_test, file=paste0(X_TEST_PATH, \"grd_imputed_robust.csv\"))\n",
    "write.csv(img_imputed_standard_test, file=paste0(X_TEST_PATH, \"grd_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_dropped, file=paste0(X_TEST_PATH, \"grd_dropped_raw.csv\"))\n",
    "write.csv(img_dropped_minmax, file=paste0(X_TEST_PATH, \"grd_dropped_minmax.csv\"))\n",
    "write.csv(img_dropped_robust, file=paste0(X_TEST_PATH, \"grd_dropped_robust.csv\"))\n",
    "write.csv(img_dropped_standard, file=paste0(X_TEST_PATH, \"grd_dropped_standard.csv\"))\n",
    "\n",
    "write.csv(img_raw_test, file=paste0(X_TEST_PATH, \"grd_raw_raw.csv\"))\n",
    "write.csv(img_raw_minmax_test, file=paste0(X_TEST_PATH, \"grd_raw_minmax.csv\"))\n",
    "write.csv(img_raw_robust_test, file=paste0(X_TEST_PATH, \"grd_raw_robust.csv\"))\n",
    "write.csv(img_raw_standard_test, file=paste0(X_TEST_PATH, \"grd_raw_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_clipped_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_clipped_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_clipped_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_imputed_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_imputed_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_imputed_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_raw_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_raw_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_raw_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"grd_raw_standard.csv\"))\n",
    "\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"grd_dropped_raw.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"grd_dropped_minmax.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"grd_dropped_robust.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"grd_dropped_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_clipped_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_clipped_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_clipped_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_clipped_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_imputed_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_imputed_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_imputed_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_imputed_standard.csv\"))\n",
    "\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_raw_raw.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_raw_minmax.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_raw_robust.csv\"))\n",
    "write.csv(img_targets_test, file=paste0(Y_TEST_PATH, \"img_raw_standard.csv\"))\n",
    "\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"img_dropped_raw.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"img_dropped_minmax.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"img_dropped_robust.csv\"))\n",
    "write.csv(grd_targets_dropped, file=paste0(Y_TEST_PATH, \"img_dropped_standard.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_raw <- read.csv(\"Data/gs/x_train/bison_gulch.csv\", header = TRUE)\n",
    "bg_targets <- read.csv(\"Data/gs/y_train/bison_gulch.csv\")$bg_speclib.FncGrp1\n",
    "\n",
    "bz_raw <- read.csv(\"Data/gs/x_train/bonanza.csv\", header = TRUE)\n",
    "bz_targets <- read.csv(\"Data/gs/y_train/bonanza.csv\")$bz_speclib.FncGrp1\n",
    "\n",
    "ch_raw <- read.csv(\"Data/gs/x_train/chatanika.csv\", header = TRUE)\n",
    "ch_targets <- read.csv(\"Data/gs/y_train/chatanika.csv\")$ch_speclib.FncGrp1\n",
    "\n",
    "em_raw <- read.csv(\"Data/gs/x_train/eight_mile.csv\", header = TRUE)\n",
    "em_targets <- read.csv(\"Data/gs/y_train/eight_mile.csv\")$em_speclib.FncGrp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(bg_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(length(bg_targets))\n",
    "print(length(bz_targets))\n",
    "print(length(ch_targets))\n",
    "print(length(em_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_permutation <-  permute::shuffle(length(bg_targets)) %>% as.vector()\n",
    "bg_sample <- create_stratified_sample(\n",
    "    bg_targets, \n",
    "    permutation = bg_permutation,\n",
    "    samples_per_pft = 18)\n",
    "\n",
    "bz_permutation <-  permute::shuffle(length(bz_targets)) %>% as.vector()\n",
    "bz_sample <- create_stratified_sample(\n",
    "    bz_targets, \n",
    "    permutation = bz_permutation,\n",
    "    samples_per_pft = 18)\n",
    "\n",
    "ch_permutation <-  permute::shuffle(length(ch_targets)) %>% as.vector()\n",
    "ch_sample <- create_stratified_sample(\n",
    "    ch_targets, \n",
    "    permutation = ch_permutation,\n",
    "    samples_per_pft = 18)\n",
    "\n",
    "em_permutation <-  permute::shuffle(length(em_targets)) %>% as.vector()\n",
    "em_sample <- create_stratified_sample(\n",
    "    em_targets, \n",
    "    permutation = em_permutation,\n",
    "    samples_per_pft = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(bg_permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_targets_test <- bg_targets[bg_permutation][bg_sample]\n",
    "bg_targets_train <- bg_targets[bg_permutation][-bg_sample]\n",
    "bg_raw_test <- bg_raw[bg_permutation,][bg_sample,]\n",
    "bg_raw_train <- bg_raw[bg_permutation,][-bg_sample,]\n",
    "\n",
    "bz_targets_test <- bz_targets[bz_permutation][bz_sample]\n",
    "bz_targets_train <- bz_targets[bz_permutation][-bz_sample]\n",
    "bz_raw_test <- bz_raw[bz_permutation,][bz_sample,]\n",
    "bz_raw_train <- bz_raw[bz_permutation,][-bz_sample,]\n",
    "\n",
    "ch_targets_test <- ch_targets[ch_permutation][ch_sample]\n",
    "ch_targets_train <- ch_targets[ch_permutation][-ch_sample]\n",
    "ch_raw_test <- ch_raw[ch_permutation,][ch_sample,]\n",
    "ch_raw_train <- ch_raw[ch_permutation,][-ch_sample,]\n",
    "\n",
    "em_targets_test <- em_targets[em_permutation][em_sample]\n",
    "em_targets_train <- em_targets[em_permutation][-em_sample]\n",
    "em_raw_test <- em_raw[em_permutation,][em_sample,]\n",
    "em_raw_train <- em_raw[em_permutation,][-em_sample,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "bg_targets_test %>% as.factor() %>% table()\n",
    "bz_targets_test %>% as.factor() %>% table()\n",
    "ch_targets_test %>% as.factor() %>% table()\n",
    "em_targets_test %>% as.factor() %>% table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(bg_targets_test, file=paste0(Y_TRAIN_PATH, \"bison_gulch_stratified.csv\"), row.names=FALSE )\n",
    "write.csv(bg_raw_test, file=paste0(X_TRAIN_PATH, \"bison_gulch_stratified.csv\"), row.names = FALSE )\n",
    "\n",
    "write.csv(bz_targets_test, file=paste0(Y_TRAIN_PATH, \"bonanza_stratified.csv\"), row.names=FALSE )\n",
    "write.csv(bz_raw_test, file=paste0(X_TRAIN_PATH, \"bonanza_stratified.csv\"), row.names = FALSE )\n",
    "\n",
    "write.csv(ch_targets_test, file=paste0(Y_TRAIN_PATH, \"chatanika_stratified.csv\"), row.names=FALSE )\n",
    "write.csv(ch_raw_test, file=paste0(X_TRAIN_PATH, \"chatanika_stratified.csv\"), row.names = FALSE )\n",
    "\n",
    "write.csv(em_targets_test, file=paste0(Y_TRAIN_PATH, \"eight_mile_stratified.csv\"), row.names=FALSE )\n",
    "write.csv(em_raw_test, file=paste0(X_TRAIN_PATH, \"eight_mile_stratified.csv\"), row.names = FALSE )\n",
    "\n",
    "write.csv(bg_targets_train, file=paste0(X_TEST_PATH, \"bison_gulch.csv\"))\n",
    "write.csv(bg_raw_train, file=paste0(Y_TEST_PATH, \"bison_gulch.csv\"))\n",
    "\n",
    "write.csv(bz_targets_train, file=paste0(X_TEST_PATH, \"bonanza.csv\"))\n",
    "write.csv(bg_raw_train, file=paste0(Y_TEST_PATH, \"bonanza.csv\"))\n",
    "\n",
    "write.csv(ch_targets_train, file=paste0(X_TEST_PATH, \"chatanika.csv\"))\n",
    "write.csv(ch_raw_train, file=paste0(Y_TEST_PATH, \"chatanika.csv\"))\n",
    "\n",
    "write.csv(em_targets_train, file=paste0(X_TEST_PATH, \"eight_mile.csv\"))\n",
    "write.csv(em_raw_train, file=paste0(Y_TEST_PATH, \"eight_mile.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# need to write the targets fror training\n",
    "clip_transform <- create_clip_transform(\n",
    "    img_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "save(clip_transform, file=\"./mle/clip_transform.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clipped_2 <- clip_transform(img_raw)# clipped 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Correction\n",
    "\n",
    "In this section, we create the models (and do some data transforms) to make the sensor-correction models and create the corrected data (only three times).  \n",
    "\n",
    "We do this first for the raw (including outliers) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_resampled_to_match_img_bands <- resample_df(\n",
    "    grd_bands,\n",
    "    min_wavelength = 398,\n",
    "    max_wavelength = 999,\n",
    "    delta=1,\n",
    "    drop_existing = TRUE\n",
    ")\n",
    "head(grd_resampled_to_match_img_bands)\n",
    "head(img_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(grd_resampled_to_match_img_bands) <- colnames(img_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_resampled_to_match_img_bands$targets <- grd_targets\n",
    "img_bands_with_targets <- img_bands\n",
    "img_bands_with_targets$targets <- img_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "matched_data <- create_matched_data(\n",
    "    img_bands_with_targets,\n",
    "    grd_resampled_to_match_img_bands,\n",
    "    cols=c(\"targets\",\"targets\")# assumes joining on columns named \"targets\" in each data.frame\n",
    ")\n",
    "head(matched_data$left)\n",
    "head(matched_data$right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "correction_model <- build_columnwise_sensor_correction_model(\n",
    "    matched_data$left,\n",
    "    matched_data$right,\n",
    "    grouping_variables =c(\"targets\",\"targets\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(correction_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_corrected_bands <- apply_sensor_correction_model(\n",
    "    correction_model,\n",
    "    grd_resampled_to_match_img_bands,\n",
    "    ignore_cols=c(\"targets\")\n",
    ")\n",
    "head(grd_corrected_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_corrected_indices <- get_vegetation_indices(grd_corrected_bands, NULL)\n",
    "head(grd_corrected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_corrected_resampled_bands <- resample_df(grd_corrected_bands, drop_existing=TRUE)\n",
    "head(grd_corrected_resampled_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(\n",
    "    cbind(grd_corrected_resampled_bands, grd_corrected_indices), \n",
    "    file=paste0(X_TRAIN_PATH, \"grd_raw_corrected.csv\")\n",
    "    )\n",
    "\n",
    "# save labels also\n",
    "write.csv(\n",
    "    grd_resampled_to_match_img_bands$targets,\n",
    "    file=paste0(Y_TRAIN_PATH, \"grd_raw_corrected.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that is done, we will move on to the clipped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_resampled_to_img_clipped <- resample_df(\n",
    "    clip_outliers(grd_bands),\n",
    "    min_wavelength = 398,\n",
    "    max_wavelength = 999,\n",
    "    delta=1,\n",
    "    drop_existing = TRUE\n",
    ")\n",
    "\n",
    "colnames(grd_resampled_to_img_clipped) <- colnames(img_bands)\n",
    "\n",
    "grd_resampled_to_img_clipped$targets <- grd_targets\n",
    "img_bands_with_targets <- img_bands\n",
    "img_bands_with_targets$targets <- img_targets\n",
    "\n",
    "matched_data_clipped <- create_matched_data(\n",
    "    img_bands_with_targets,\n",
    "    grd_resampled_to_img_clipped,\n",
    "    cols=c(\"targets\",\"targets\")# assumes joining on columns named \"targets\" in each data.frame\n",
    ")\n",
    "\n",
    "correction_model <- build_columnwise_sensor_correction_model(\n",
    "    matched_data_clipped$left,\n",
    "    matched_data_clipped$right\n",
    ")\n",
    "grd_corrected_clipped_bands <- apply_sensor_correction_model(\n",
    "    correction_model,\n",
    "    grd_resampled_to_match_img_bands,\n",
    "    ignore_cols=c(\"targets\")\n",
    ")\n",
    "grd_corrected_clipped_indices <- get_vegetation_indices(grd_corrected_bands, NULL)\n",
    "grd_corrected_clipped_resampled_bands <- resample_df(grd_corrected_bands, drop_existing=TRUE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(\n",
    "    cbind(\n",
    "        grd_corrected_clipped_indices,\n",
    "        grd_corrected_clipped_resampled_bands\n",
    "    ),\n",
    "    file=paste0(\n",
    "        X_TRAIN_PATH,\n",
    "        \"grd_clipped_corrected.csv\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# save labels also\n",
    "write.csv(\n",
    "    grd_resampled_to_match_img_bands$targets,\n",
    "    file=paste0(Y_TRAIN_PATH, \"grd_clipped_corrected.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the dropped outlier one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes for later: should probably try PCA here.  clip -> scale -> PCA -> subset (and scale again for models like SVM and kNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to be continued"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
