{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, custom = NULL, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: PLS-LDA (plsgenomics)\"))\n",
    "    print(paste0(\"Data Index: \",custom))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(\n",
    "    model_id, \n",
    "    outlier = \"\", \n",
    "    preprocessing=\"\",\n",
    "    source=\"\", \n",
    "    weight = \"\",\n",
    "    n = \"\",\n",
    "    oob_error = \"\",\n",
    "    accuracy = \"\",\n",
    "    r2 = \"\",\n",
    "    chi2prob = \"\",\n",
    "    logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- \"source,outliers,preprocessing,weight,n,oob,accuracy,r2,chi2prob,model_id\"\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        source,\n",
    "        outlier,\n",
    "        preprocessing,\n",
    "        weight,\n",
    "        n,\n",
    "        oob_error,\n",
    "        accuracy,\n",
    "        r2,\n",
    "        chi2prob,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \",\", model_id)\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_pls_lda <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    test_df, \n",
    "    test_labels,\n",
    "    n = 32,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = targets_to_weights,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    save_path = \"./mle/models/gs/\",\n",
    "    seed = NULL,\n",
    "    log_string = \"\"\n",
    "){\n",
    "\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    x_test <- test_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "        x_test <- preprocess_fn(x_test)\n",
    "    }\n",
    "\n",
    "    if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "        levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "        }\n",
    "        \n",
    "    train_ctrl <- caret::trainControl(\n",
    "        method = \"repeatedcv\",\n",
    "        number = 10,\n",
    "        sampling = 'up',\n",
    "        repeats = 3\n",
    "    )\n",
    "    \n",
    "    pls_model <- caret::train(\n",
    "        x_train, \n",
    "        train_labels, \n",
    "        maxit = 100000,\n",
    "        method=\"pls\",\n",
    "        weights = weight_fn(train_labels),\n",
    "        trControl = train_ctrl,\n",
    "        tuneLength = n\n",
    "    )\n",
    "\n",
    "    print(pls_model)\n",
    "\n",
    "    save(\n",
    "        pls_model,\n",
    "        file = file.path(save_path, paste0(model_id, \".rda\"))\n",
    "    )\n",
    "\n",
    "    # create predictions (ranger)\n",
    "    model_predictions <- predict(\n",
    "            pls_model, \n",
    "            newdata = x_test\n",
    "        )\n",
    "\n",
    "    print(model_predictions)\n",
    "\n",
    "\n",
    "    # generate the confusion matrix\n",
    "\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        test_labels,\n",
    "        model_predictions %>% as.factor(),\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "    log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            custom = log_string,\n",
    "            distribition = model_predictions %>% as.factor() %>% table(),\n",
    "            logpath = \"./gs_pls_n.log\")\n",
    "\n",
    "    return(\n",
    "        list(\n",
    "                model = pls_model,\n",
    "                confusion = confusion_matrix %>% as.list()\n",
    "                )\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "apply_model.pls_lda <- function(x, model,  ...){\n",
    "    \n",
    "    if(\"x\" %in% colnames(x) && \"y\" %in% colnames(x)){\n",
    "        print(\"Spatial ifnormation detected, ignoring....\")\n",
    "        target_df <- subset(x, select=-c(x,y))\n",
    "        predictions <- predict(model, newdata = target_df) %>% as.data.frame()\n",
    "\n",
    "        prediction_df <- subset(x, select=c(x,y))\n",
    "        prediction_df$z <- predictions\n",
    "\n",
    "    } else {\n",
    "        prediction_df <- predict(model, newdata = x) %>% as.data.frame()\n",
    "    }\n",
    "\n",
    "    return(prediction_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write_pls_lda_model <- function(object, save_path, uuid = NULL){\n",
    "    model_id <- uuid\n",
    "    if(is.null(model_id)){\n",
    "        model_id <- uuid::UUIDgenerate()\n",
    "    }\n",
    "\n",
    "    save(x_train, x_train_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_model <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    test_df, \n",
    "    test_labels,\n",
    "    n = 10,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = targets_to_weights,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    seed = NULL,\n",
    "    log_string = \"\"\n",
    "){\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    x_test <- test_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "        x_test <- preprocess_fn(x_test)\n",
    "    }\n",
    "\n",
    "    model <- ranger::ranger(\n",
    "            num.trees = ntree,\n",
    "            case.weights = weight_fn(train_labels),\n",
    "            classification = TRUE,\n",
    "            x=x_train,\n",
    "            y=train_labels\n",
    "        )\n",
    "\n",
    "    if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "            levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "            }\n",
    "\n",
    "    # create predictions (ranger)\n",
    "        model_predictions <- predict(\n",
    "            model, \n",
    "            x_test\n",
    "        )$prediction %>% as.factor()\n",
    "\n",
    "        # generate the confusion matrix\n",
    "\n",
    "        confusion_matrix <- caret::confusionMatrix(\n",
    "            model_predictions, \n",
    "            test_labels,\n",
    "            mode = \"everything\"\n",
    "        )\n",
    "\n",
    "        # generate an id to uniquely identify the model\n",
    "        #model_id <- uuid::UUIDgenerate()\n",
    "\n",
    "        # append performance data to the logs for later comparison\n",
    "        log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            custom = log_string,\n",
    "            distribition = model_predictions %>% as.factor() %>% table(),\n",
    "            logpath = \"./gs_pls_lda.log\")\n",
    "\n",
    "        # track what levels are associated with the UUID\n",
    "\n",
    "        # save the model using the model UUID\n",
    "        save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n",
    "        \n",
    "        return(\n",
    "            list(\n",
    "                model = model,\n",
    "                confusion = confusion_matrix %>% as.list()\n",
    "                )\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "base_paths <- c(\n",
    "    \"img_only_bands.csv\",\n",
    "    \"grd_only_bands.csv\",\n",
    "    \"corrected_and_img_only_bands.csv\",\n",
    "    \"grd_corrected_only_bands.csv\",# include veg indices\n",
    "    \"img_raw_raw.csv\",\n",
    "    \"grd_raw_raw.csv\",\n",
    "    \"corrected_and_img.csv\",\n",
    "    \"img_indices_only.csv\",# include veg indices\n",
    "    \"grd_raw_corrected.csv\",\n",
    "    \"grd_indices_only.csv\"\n",
    ")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculate_posterior_weights <- function(validation_path =\"figures/merged_validation_s.csv\" ){\n",
    "\n",
    "    validation_df <- read.csv(validation_path, header = TRUE)\n",
    "    #print(head(validation_df))\n",
    "\n",
    "    total_observations <- sum(validation_df$validation_counts)\n",
    "    #print(total_observations)\n",
    "    weights <- (1/ validation_df$validation_prop)\n",
    "    #print(validation_df$validation_prop)\n",
    "\n",
    "    total_by_fg1 <- aggregate(\n",
    "        x = validation_df$validation_counts,\n",
    "        by = list(validation_df$key),\n",
    "        FUN = sum\n",
    "    )\n",
    "\n",
    "    fg1_weight_list <- list()\n",
    "\n",
    "    for( row_idx in seq(nrow(total_by_fg1))){\n",
    "        name <- total_by_fg1$Group.1[[row_idx]]\n",
    "        value <- total_by_fg1$x[[row_idx]]\n",
    "        fg1_weight_list[name] <- value\n",
    "    }\n",
    "    \n",
    "    return(fg1_weight_list)\n",
    "}\n",
    "\n",
    "get_posterior_weights_from_targets <- function(target_factor, posterior_weight = calculate_posterior_weights()){\n",
    "    unbiased_weights <- targets_to_weights(target_factor)\n",
    "\n",
    "    target_name_char <- target_factor %>% as.character()\n",
    "\n",
    "    output_weights <- seq_along(target_factor)\n",
    "\n",
    "    for(i in seq_along(target_factor)){\n",
    "        if(posterior_weight[[target_name_char[[i]]]] > 0){\n",
    "            fg1_weight <- 1 / posterior_weight[[target_name_char[[i]]]]\n",
    "        } else {\n",
    "            fg1_weight <- 0\n",
    "        }\n",
    "        output_weights[[i]] <- unbiased_weights[[i]] * fg1_weight\n",
    "    }\n",
    "\n",
    "    return(output_weights)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "\n",
    "Peter\n",
    "* Increasing number of trees will improve the accuracy/validation mismatch\n",
    "* bias in \n",
    "\n",
    "Ken\n",
    "* decreasing the number of the trees will decrease the impact of the posterior weighting on chi-squared statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "outlier_functions <- list(\n",
    "    #clip = load_model(\"./mle/clip_transform.rda\"),\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)}# no transform\n",
    ")\n",
    "\n",
    "outlier_treatments <- c(\n",
    "    \"no_treatment\",\n",
    "    \"clip\"\n",
    ")\n",
    "\n",
    "preprocess_functions <- list(\n",
    "    no_treatment = function(x, ignore_cols = NULL){return(x)},# no transform\n",
    "    min_max = columnwise_min_max_scale,\n",
    "    robust = columnwise_robust_scale,\n",
    "    standard = standardize_df\n",
    ")\n",
    "\n",
    "weight_functions <- list(\n",
    "    posterior = get_posterior_weights_from_targets,\n",
    "    balanced = targets_to_weights,\n",
    "    no_treatment = function(x){return(NULL)}# No weights\n",
    ")\n",
    "weight_treatments <- c(\n",
    "    \"balanced\"#,\n",
    "    #\"no_treatment\",\n",
    "    #\"posterior\"\n",
    ")\n",
    "\n",
    "preprocessing_treatments <- c(\n",
    "    \"no_treatment\"#,\n",
    "    #\"standard\",\n",
    "    #\"min_max\",\n",
    "    #\"robust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "num_components <- c(\n",
    "    1,2,4,6,8,10,12,14,16,18,20,24,32,50,64,75,100,128,200,256,512,1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test_data <- subset(read.csv(\"Data/gs/x_test/img_raw_raw.csv\"), select = -c(X))\n",
    "test_labels <- read.csv(\"Data/gs/y_test/img_raw_raw.csv\")$x %>% as.factor()\n",
    "#train_labels <- read.csv(\"Data/gs/y_train/img_raw_raw.csv\")$x %>% as.factor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(filepath in base_paths){\n",
    "    train_data <- subset(read.csv(paste0(\"Data/gs/x_train/\", filepath)), select = -c(X))\n",
    "    labels <- read.csv(paste0(\"Data/gs/y_train/\", filepath))$x %>% as.factor()\n",
    "\n",
    "    for(o_treatment in outlier_treatments){\n",
    "        for(p_treatment in preprocessing_treatments){\n",
    "            for(w_treatment in weight_treatments){\n",
    "                for(n in num_components){\n",
    "\n",
    "\n",
    "                print(p_treatment)\n",
    "                print(\"Number of columns in train and test:\")\n",
    "                print(ncol(train_data))\n",
    "                print(ncol(test_data))\n",
    "                print(\"Number of rows in train and number of labels:\")\n",
    "                print(nrow(train_data))\n",
    "                print(length(labels))\n",
    "\n",
    "                model_id <- uuid::UUIDgenerate()\n",
    "                save_path <- paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "                if(!dir.exists(save_path)){\n",
    "                    dir.create(save_path)\n",
    "                }\n",
    "\n",
    "                rf_model_results <- train_pls_lda(\n",
    "                    train_data, \n",
    "                    labels, \n",
    "                    test_data,\n",
    "                    test_labels,\n",
    "                    n = n,\n",
    "                    outlier_fn = outlier_functions[[o_treatment]],\n",
    "                    preprocess_fn = preprocess_functions[[p_treatment]],\n",
    "                    weight_fn = weight_functions[[w_treatment]],\n",
    "                    model_id = model_id,\n",
    "                    seed=61718,\n",
    "                    log_string = paste(n, filepath, o_treatment, p_treatment, w_treatment)\n",
    "                )\n",
    "                print(rf_model_results)\n",
    "\n",
    "                rf_model <- rf_model_results$model\n",
    "                acc <- as.list(rf_model_results$confusion$overall)$Accuracy\n",
    "                print(acc)\n",
    "\n",
    "\n",
    "\n",
    "                results <- validate_model(\n",
    "                    rf_model, \n",
    "                    save_path, \n",
    "                    outlier_processing = outlier_functions[[o_treatment]],\n",
    "                    transform_type = preprocess_functions[[p_treatment]],\n",
    "                )\n",
    "\n",
    "                aggregated_results <- aggregate_results(save_path)\n",
    "\n",
    "                # calculate validation statistics\n",
    "                chi2 <- calculate_chi_squared_probability(aggregated_results)\n",
    "                r2 <- calculate_validation_r2(aggregated_results)\n",
    "\n",
    "                add_model_to_manifest(\n",
    "                    model_id = model_id,\n",
    "                    outlier = o_treatment,\n",
    "                    preprocessing = p_treatment,\n",
    "                    source = filepath,\n",
    "                    weight = w_treatment,\n",
    "                    n = n,\n",
    "                    oob_error = rf_model$prediction.error,\n",
    "                    accuracy = acc,\n",
    "                    r2 = r2,\n",
    "                    chi2prob = chi2,\n",
    "                    logpath=\"./gs_manifest_pls_ncomp.csv\"\n",
    "                )\n",
    "\n",
    "                plot_by_pft(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"aggregate.html\"),\n",
    "                    open = FALSE,\n",
    "                    image_path = NULL\n",
    "                )\n",
    "            #\n",
    "                write_validation_table(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"table.html\"),\n",
    "                    open = FALSE\n",
    "                )\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sink(NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(setdiff(colnames(test_data), colnames(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
