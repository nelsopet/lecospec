{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks use their location as their working directory, so\n",
    "# if we are in a subfolder, move to the main folder.  \n",
    "# This however can safely be run multiple times\n",
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)\n",
    "library(class)\n",
    "library(caret)\n",
    "library(vegan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# spectral library\n",
    "base_path <- \"./Output/C_001_SC3_Cleaned_SpectralLib.csv\"\n",
    "veg_index_path <- \"./Data/D_002_SpecLib_Derivs.csv\"\n",
    "speclib <- read.csv(base_path)\n",
    "veg_indices <- read.csv(veg_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Targets \n",
    "targets <- veg_indices[!is.na(veg_indices$Functional_group1),\"Functional_group1\"] %>% as.factor()\n",
    "# weights\n",
    "weights_by_pft <- targets_to_weights(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# image-based validation\n",
    "uav_speclib_df <- read.csv(\n",
    "    \"Data/Ground_Validation/PFT_image_spectra/PFT_Image_SpectralLib_Clean_unsmoothed.csv\", \n",
    "    header = TRUE)\n",
    "image_validation <- uav_speclib_df[,16:(ncol(uav_speclib_df) - 1)]\n",
    "validation_labels <- uav_speclib_df$FncGrp1 %>% as.factor()\n",
    "levels(validation_labels) <- c(\n",
    "    levels(validation_labels),\n",
    "    \"Forb\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base transformation\n",
    "This removes infinity, outliers and NAs from the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "numeric_data <- veg_indices[!is.na(veg_indices$Functional_group1),35:195]\n",
    "numeric_data <- inf_to_na(numeric_data)\n",
    "imputed_data_1 <- impute_spectra(numeric_data)\n",
    "imputed_data_no_outliers <- outliers_to_na(imputed_data_1)\n",
    "imputed_data <- impute_spectra(imputed_data_no_outliers)\n",
    "outlier_indices <- detect_outliers_columnwise(imputed_data[,1:95])\n",
    "filtered_data <- imputed_data[!outlier_indices,]\n",
    "hist(dist(as.matrix(imputed_data)))\n",
    "min_max_scaled_data <- columnwise_min_max_scale(imputed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Image-based Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "veg_index_names <- read.csv(\"assets/vegIndicesUsed.csv\")$x\n",
    "validation_indices <- get_vegetation_indices(image_validation, NULL)\n",
    "# drop NAs\n",
    "\n",
    "validation_indices <- inf_to_na(validation_indices)\n",
    "validation_indices <- impute_spectra(validation_indices)\n",
    "validation_indices <- outliers_to_na(validation_indices)\n",
    "validation_indices <- impute_spectra(validation_indices)\n",
    "\n",
    "\n",
    "min_max_scaled_validation <- columnwise_min_max_scale(validation_indices)\n",
    "\n",
    "#hist(as.matrix(min_max_scaled_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(summary(min_max_scaled_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "image_weights <- targets_to_weights(validation_labels %>% as.factor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "This is where we calcuate PCA for the ground and image spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# fit a PCA to the ground spectra\n",
    "pca_fit <- stats::prcomp(imputed_data[,1:(ncol(numeric_data) - 66)], center = FALSE, scale. = FALSE)\n",
    "print(summary(pca_fit))\n",
    "pca_training_data <- predict(pca_fit, imputed_data[,1:(ncol(numeric_data) - 66)])[,1:64]\n",
    "boxplot(vegan::scores(pca_training_data)[,2]~targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "This cell standardizes the input to center at zero with standard deviation one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "indice_standardizer <- caret::preProcess(imputed_data[,1:95])\n",
    "standardized_indices <- predict(indice_standardizer, imputed_data[,1:95])\n",
    "\n",
    "val_standardizer <- caret::preProcess(validation_indices)\n",
    "standardized_validation <- predict(val_standardizer, validation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hist(standardized_indices$Carter, breaks = 20)\n",
    "hist(standardized_validation$Carter, breaks = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaling\n",
    "This executes the min-man scalaing (to make the data on the scale [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# plots\n",
    "hist(min_max_scaled_validation %>% as.matrix())\n",
    "hist(min_max_scaled_data %>% as.matrix())\n",
    "pca_validation_data <- predict(pca_fit, validation_indices[!validation_outliers,])[,1:64] %>% as.data.frame()\n",
    "boxplot(vegan::scores(pca_validation_data)[,2]~validation_labels[!validation_outliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Tests of Transferrability\n",
    "These next few cells test whether the veg indices are similarly distributed (i.e. could be samples drawn from the same distribution)\n",
    "\n",
    "The hypothesis is that columns (veg indices) that pass this test can safely be used across models and conditions (are transferrable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"Functions/lecospectR.R\")\n",
    "ks_test_results <- test_transferrability(min_max_scaled_data, min_max_scaled_validation)\n",
    "print(ks_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "Examine the clusters in the data via *t*-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(Rtsne)\n",
    "unique_indices <- imputed_data[!duplicated(imputed_data),1:95]\n",
    "normalized_veg_indices <- Rtsne::normalize_input(\n",
    "    unique_indices %>% \n",
    "    as.matrix()\n",
    "    )\n",
    "embedding_2D <- Rtsne::Rtsne(normalized_veg_indices)\n",
    "print(names(embedding_2D))\n",
    "\n",
    "plot(embedding_2D$Y, col = as.factor(targets))\n",
    "par(xpd=T)\n",
    "legend(\"topright\", legend = unique(targets), col = seq_along(unique(targets)),pch = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Quantization Classifier\n",
    "This fits a LVQ classifier to the data and then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(length(validation_labels))\n",
    "print(nrow(min_max_scaled_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# method 1 - transfers with 23% accuracy, which is one of the best actually\n",
    "library(class)\n",
    "codeBook <-  lvqinit(\n",
    "    min_max_scaled_data[,1:95], \n",
    "    targets, \n",
    "10)\n",
    "code_book_train <- class::olvq1(min_max_scaled_data[,1:95], targets, codeBook)\n",
    "prediction <- class::lvqtest(code_book_train, min_max_scaled_data[,1:95])\n",
    "lvq_conf <- caret::confusionMatrix(prediction, targets, mode = \"everything\")\n",
    "\n",
    "#print(lvq_conf)\n",
    "\n",
    "image_prediction <- class::lvqtest(code_book_train, min_max_scaled_validation)\n",
    "\n",
    "lvq_validation_conf <- caret::confusionMatrix(image_prediction, validation_labels, mode = \"everything\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(lvq_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(lvq_validation_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Perform an 80-20 split on the data (use the split on the fly during the grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "grd_train_idx <- caTools::sample.split(targets, SplitRatio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "img_train_idx <- caTools::sample.split(validation_labels, SplitRatio = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "trains a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rf_model <- ranger::ranger(\n",
    "    num.trees = 256,\n",
    "    case.weights = image_weights,\n",
    "    classification = TRUE,\n",
    "    x = validation_indices,\n",
    "    y = validation_labels\n",
    ")\n",
    "\n",
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predictions <- predict(rf_model, validation_indices)$predictions %>% \n",
    "    as.factor()\n",
    "confusion_matrix <- caret::confusionMatrix(\n",
    "    predictions, \n",
    "    validation_labels, \n",
    "    mode = \"everything\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "This next section defines all the essentials for the grid search across our different candidate models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidates\n",
    "\n",
    "### Models\n",
    "* Random Forest\n",
    "* Learned Vector Quantization (LVQ)\n",
    "* k-Nearest Neighbor (kNN)\n",
    "\n",
    "Could also consider Support Vector Machine (SVM), Gradient Boosted Trees (e.g. LightGBM, XGBoost), matched filtering, Logistic Regression, etc.\n",
    "\n",
    "### Data/Transformations\n",
    "\n",
    "For each of the image/training data sets, test the following:\n",
    "* raw, \n",
    "* raw (no outliers)\n",
    "* standardized (z-score standardization)\n",
    "* standardized (z-score standardization, no outliers)\n",
    "* min-max scaled\n",
    "* min-max scaled (no outliers)\n",
    "* PCA\n",
    "* PCA no outliers\n",
    "\n",
    "Need to also vary how many columns are included in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# define the data sets to loop over\n",
    "gs_train <- list(\n",
    "    min_max_scaled_data[,1:95],\n",
    "    min_max_scaled_validation[img_train_idx,],\n",
    "    standardized_indices,\n",
    "    standardized_validation[img_train_idx,]\n",
    "    pca_training_data,\n",
    "    pca_validation_data[img_train_idx,]\n",
    ")\n",
    "\n",
    "gs_test <- list(\n",
    "    min_max_scaled_validation[-img_train_idx,],\n",
    "    min_max_scaled_validation[-img_train_idx,],\n",
    "    standardized_validation[-img_train_idx,],\n",
    "    standardized_validation[-img_train_idx,],\n",
    "    pca_validation_data[-img_train_idx],\n",
    "    pca_validation_data[-img_train_idx]\n",
    "\n",
    ")\n",
    "\n",
    "gs_train_labels <- list(\n",
    "    targets,\n",
    "    validation_labels[img_train_idx],\n",
    "    targets,\n",
    "    validation_labels[img_train_idx],\n",
    "    targets,\n",
    "    validation_labels[img_train_idx],\n",
    ")\n",
    "\n",
    "gs_test_labels <- list(\n",
    "    validation_labels[-img_train_idx],\n",
    "    validation_labels[-img_train_idx],\n",
    "    validation_labels[-img_train_idx],\n",
    "    validation_labels[-img_train_idx],\n",
    "    validation_labels[-img_train_idx],\n",
    "    validation_labels[-img_train_idx]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gs_methods <- list(\n",
    "    \"svmLinear\",\n",
    "    #\"rmda\",\n",
    "    \"rf\",\n",
    "    \"svmRadialWeights\",\n",
    "    \"gbm\",\n",
    "    \"hda\"# heteroscedastic discriminant analysis\n",
    ")\n",
    "# add: PLS-LDA, kNN, SVM+poly Kernel, SVM+Exp Kernel, more boosting, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gs_weight_text <- c(\n",
    "    \"prior weights\",\n",
    "    NULL\n",
    ")\n",
    "\n",
    "gs_weights <- list(\n",
    "    weights_by_pft,\n",
    "    image_weights,\n",
    "    weights_by_pft,\n",
    "    image_weights,\n",
    "    weights_by_pft,\n",
    "    image_weights\n",
    ")\n",
    "\n",
    "fit_ctrl <- caret::trainControl(\n",
    "    method = \"repeatedcv\",\n",
    "    number = 10,\n",
    "    repeats = 3,\n",
    "    classProbs = TRUE,\n",
    "    allowParallel = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(i in seq_along(gs_train)){\n",
    "    for(j in seq_along(gs_methods)){\n",
    "        # train and print intermediate results to console\n",
    "        df <- data.frame(gs_train[[i]])\n",
    "        df$targets <-  as.factor(gs_train_labels[[i]]) \n",
    "        print(\"Beginning Training\")\n",
    "        model <- train(\n",
    "           targets ~ ., \n",
    "            data = df,\n",
    "            method = gs_methods[[j]],\n",
    "            trControl = fit_ctrl,\n",
    "            weights = gs_weights[[i]]\n",
    "            verbose = TRUE\n",
    "        )\n",
    "        print(model)\n",
    "\n",
    "        model_predictions <- predict(\n",
    "            model, \n",
    "            gs_test[[i]]\n",
    "        ) %>% as.factor()\n",
    "        \n",
    "        test_labels <- gs_test_labels[[i]] %>% as.factor()\n",
    "        levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "\n",
    "        confusion_matrix <- caret::confusionMatrix(\n",
    "            model_predictions, \n",
    "            test_labels,\n",
    "            mode = \"everything\"\n",
    "        )\n",
    "\n",
    "        # append performance data to the logs for later comparison\n",
    "        sink(file = \"mle/logs.txt\", append = TRUE)\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\"---------------------- Model Data ---------------------\")\n",
    "        \n",
    "        print(paste0(\"Model Type: \", gs_methods[[j]]))\n",
    "        print(paste0(\"Data Index: \",i))\n",
    "        print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "        print(confusion_matrix)\n",
    "        print(\"\\n\")\n",
    "        print(\"---------------------- Class Distribution ---------------------\")\n",
    "        print(model_predictions %>% as.factor() %>% table())\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\"\\n\\n\")\n",
    "        sink(NULL)\n",
    "\n",
    "        \n",
    "        save(model, file = paste0(\"mle/models/gs/model_\", i, \"type_\", j, \".rda\"))\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "These are the results of the grid search on the basics.  High performing models get to go through validation\n",
    "\n",
    "## Top performers:\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
