{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Calling all models, far and wide!  Now is the time to battle to the DEATH!!!!\n",
    "\n",
    "Just kidding, this is just a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks use their location as their working directory, so\n",
    "# if we are in a subfolder, move to the main folder.  \n",
    "# This however can safely be run multiple times\n",
    "#setwd(M:/lecospec/lecospec)\n",
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)\n",
    "# some features of this notebook will use this in the future, maybe.  I hope so, at least.\n",
    "library(IRdisplay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data file names\n",
    "\n",
    "This loads the data file names.  These are assumed to be the same across training data, labels, test data and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH <- \"Data/gs/\"\n",
    "X_TRAIN_PATH <- paste0(BASE_PATH, \"x_train/\")\n",
    "Y_TRAIN_PATH <- paste0(BASE_PATH, \"y_train/\")\n",
    "\n",
    "X_TEST_PATH <- paste0(BASE_PATH, \"x_test/\")\n",
    "Y_TEST_PATH <- paste0(BASE_PATH, \"y_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "training_data <- list.files(X_TRAIN_PATH)\n",
    "#training_labels <- sort(list.files(\"Data/gs/y_train/\"))# sort alphabetically to keep the files in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"grd_clipped_corrected.csv\" \"grd_clipped_minmax.csv\"   \n",
      " [3] \"grd_clipped_raw.csv\"       \"grd_clipped_robust.csv\"   \n",
      " [5] \"grd_clipped_standard.csv\"  \"grd_dropped_minmax.csv\"   \n",
      " [7] \"grd_dropped_raw.csv\"       \"grd_dropped_robust.csv\"   \n",
      " [9] \"grd_dropped_standard.csv\"  \"grd_imputed_minmax.csv\"   \n",
      "[11] \"grd_imputed_raw.csv\"       \"grd_imputed_robust.csv\"   \n",
      "[13] \"grd_imputed_standard.csv\"  \"grd_raw_corrected.csv\"    \n",
      "[15] \"grd_raw_minmax.csv\"        \"grd_raw_raw.csv\"          \n",
      "[17] \"grd_raw_robust.csv\"        \"grd_raw_standard.csv\"     \n",
      "[19] \"img_clipped_minmax.csv\"    \"img_clipped_raw.csv\"      \n",
      "[21] \"img_clipped_robust.csv\"    \"img_clipped_standard.csv\" \n",
      "[23] \"img_dropped_minmax.csv\"    \"img_dropped_raw.csv\"      \n",
      "[25] \"img_dropped_robust.csv\"    \"img_dropped_standard.csv\" \n",
      "[27] \"img_imputed_minmax.csv\"    \"img_imputed_raw.csv\"      \n",
      "[29] \"img_imputed_robust.csv\"    \"img_imputed_standard.csv\" \n",
      "[31] \"img_raw_minmax.csv\"        \"img_raw_raw.csv\"          \n",
      "[33] \"img_raw_robust.csv\"        \"img_raw_standard.csv\"     \n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load_data <- function(filepath){\n",
    "    data <- list()\n",
    "    train_data_path <- paste0(X_TRAIN_PATH, file)\n",
    "    train_labels_path <- paste0(Y_TRAIN_PATH, file)\n",
    "    test_labels_path <- paste0(Y_TEST_PATH, file)\n",
    "    test_data_path <- paste0(X_TEST_PATH, file)\n",
    "\n",
    "    # verify that all the paths are valid.  If not, return NULL\n",
    "    if(\n",
    "        file.exists(train_data_path) &&\n",
    "        file.exists(train_labels_path) &&\n",
    "        file.exists(test_data_path) &&\n",
    "        file.exists(test_labels_path)\n",
    "    ) {\n",
    "        # files all exist, so return the result\n",
    "        data$x_train <- read.csv(train_data_path)\n",
    "        data$y_train <- read.csv(train_labels_path)$x %>% as.factor()\n",
    "        data$x_test <- read.csv(test_data_path)\n",
    "        data$y_test <- read.csv(test_labels_path)$x %>% as.factor()\n",
    "\n",
    "        return(data)\n",
    "    } else {\n",
    "        # a file is missing, so return NULL\n",
    "        return( NULL )\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- ranger::ranger(\n",
    "        num.trees = 1000,\n",
    "        case.weights = weights_by_pft,\n",
    "        classification = TRUE,\n",
    "        x=df,\n",
    "        y=gs_train_labels[[i]]\n",
    "    )\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    model_predictions <- predict(\n",
    "        model, \n",
    "        test_df\n",
    "    )$prediction %>% as.factor()\n",
    "    \n",
    "    test_samples <- gs_samples[[i]] %>% as.factor()\n",
    "    if(!(\"Forb\" %in% levels(test_samples))){\n",
    "\n",
    "        levels(test_samples) <- c(levels(test_samples), \"Forb\")\n",
    "    }\n",
    "\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        model_predictions, \n",
    "        test_samples,\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    model_metadata <- list(\n",
    "        uuid = model_id,\n",
    "        variables = colnames(df),\n",
    "        type = \"Random Forest (Ranger)\",\n",
    "        preprocessing = gs_preprocessing[[i]],\n",
    "        saved = paste0(\"mle/models/gs/\", model_id, \".rda\"),\n",
    "        results = paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "    )\n",
    "\n",
    "    metadata_save_path <- paste0(\"mle/metadata/\", model_id, \".json\")\n",
    "    json_metadata_str <- rjson::toJSON(model_metadata)\n",
    "    write(json_metadata_str, file=metadata_save_path)\n",
    "    \n",
    "    save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "parse_name <- function(filepath){\n",
    "    name_no_extension <- stringi::stri_replace_last_fixed(filepath, \".csv\", \"\")\n",
    "    name_parts <- stringi::stri_split_fixed(name_no_extension, \"_\")\n",
    "\n",
    "    variables <- list(\n",
    "        source = name_parts[[1]]\n",
    "    )\n",
    "\n",
    "    if(length(name_parts) > 1){\n",
    "        variables$outliers <- names_parts[[2]]\n",
    "    } else {\n",
    "        variables$outliers <- NULL\n",
    "    }\n",
    "\n",
    "    if(length(name_parts) > 2){\n",
    "        variables$preprocessing <- name_parts[[3]]\n",
    "    } else {\n",
    "        variables$preprocessing <- NULL\n",
    "    }\n",
    "\n",
    "    return(variables)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(model_id, variables, logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- paste(names(variables), \"model_id\\n\", sep=\",\")\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        variables$source,\n",
    "        variables$outliers,\n",
    "        variables$preprocessing,\n",
    "        model_id,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \"\\n\")\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, custom, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: Ranger (Random Forest)\"))\n",
    "    print(paste0(\"Data Index: \",custom))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"grd_clipped_corrected.csv\"\n",
      "[1] \"grd_clipped_minmax.csv\"\n",
      "[1] \"Abiotic\"        \"Graminoid\"      \"Lichen\"         \"Moss\"          \n",
      "[5] \"ShrubDecid\"     \"ShrubEvergreen\" \"TreeBroadleaf\"  \"TreeConifer\"   \n",
      "[9] \"Forb\"          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(model_predictions, data$y_test, mode = \"everything\"):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”\n",
      "Warning message in stri_split_fixed(str, fixed, ...):\n",
      "“NAs introduced by coercion”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"grd_clipped_raw.csv\"\n",
      "[1] \"Abiotic\"        \"Graminoid\"      \"Lichen\"         \"Moss\"          \n",
      "[5] \"ShrubDecid\"     \"ShrubEvergreen\" \"TreeBroadleaf\"  \"TreeConifer\"   \n",
      "[9] \"Forb\"          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(model_predictions, data$y_test, mode = \"everything\"):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”\n",
      "Warning message in stri_split_fixed(str, fixed, ...):\n",
      "“NAs introduced by coercion”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"grd_clipped_robust.csv\"\n",
      "[1] \"Abiotic\"        \"Graminoid\"      \"Lichen\"         \"Moss\"          \n",
      "[5] \"ShrubDecid\"     \"ShrubEvergreen\" \"TreeBroadleaf\"  \"TreeConifer\"   \n",
      "[9] \"Forb\"          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(model_predictions, data$y_test, mode = \"everything\"):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”\n",
      "Warning message in stri_split_fixed(str, fixed, ...):\n",
      "“NAs introduced by coercion”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"grd_clipped_standard.csv\"\n",
      "[1] \"Abiotic\"        \"Graminoid\"      \"Lichen\"         \"Moss\"          \n",
      "[5] \"ShrubDecid\"     \"ShrubEvergreen\" \"TreeBroadleaf\"  \"TreeConifer\"   \n",
      "[9] \"Forb\"          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(model_predictions, data$y_test, mode = \"everything\"):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”\n",
      "Warning message in stri_split_fixed(str, fixed, ...):\n",
      "“NAs introduced by coercion”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"grd_dropped_minmax.csv\"\n",
      "[1] \"Abiotic\"        \"Forb\"           \"Graminoid\"      \"Lichen\"        \n",
      "[5] \"Moss\"           \"ShrubDecid\"     \"ShrubEvergreen\" \"TreeBroadleaf\" \n",
      "[9] \"TreeConifer\"   \n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in table(data, reference, dnn = dnn, ...): all arguments must have the same length\n",
     "output_type": "error",
     "traceback": [
      "Error in table(data, reference, dnn = dnn, ...): all arguments must have the same length\nTraceback:\n",
      "1. caret::confusionMatrix(model_predictions, data$y_test, mode = \"everything\")",
      "2. confusionMatrix.default(model_predictions, data$y_test, mode = \"everything\")",
      "3. table(data, reference, dnn = dnn, ...)",
      "4. stop(\"all arguments must have the same length\")"
     ]
    }
   ],
   "source": [
    "for(file in training_data){\n",
    "\n",
    "    print(file)\n",
    "    # load all the data\n",
    "    data <- load_data(file)\n",
    "\n",
    "    if(!is.null(data)){\n",
    "        \n",
    "        model <- ranger::ranger(\n",
    "            num.trees = 1000,\n",
    "            case.weights = targets_to_weights(data$y_train),\n",
    "            classification = TRUE,\n",
    "            x=data$x_train,\n",
    "            y=data$y_train\n",
    "        )\n",
    "\n",
    "        #add forb if it's in the training data to avoid mismatch\n",
    "        if((\"Forb\" %in% levels(data$y_train)) && !(\"Forb\"  %in% levels(data$y_test))){\n",
    "            levels(data$y_test) <- c(levels(data$y_test), \"Forb\")\n",
    "            }\n",
    "\n",
    "        print(levels(data$y_test))\n",
    "\n",
    "        # create predictions (ranger)\n",
    "        model_predictions <- predict(\n",
    "            model, \n",
    "            data$x_test\n",
    "        )$prediction %>% as.factor()\n",
    "\n",
    "        # generate the confusion matrix\n",
    "        confusion_matrix <- caret::confusionMatrix(\n",
    "            model_predictions, \n",
    "            data$y_test,\n",
    "            mode = \"everything\"\n",
    "        )\n",
    "\n",
    "        # generate an id to uniquely identify the model\n",
    "        model_id <- uuid::UUIDgenerate()\n",
    "\n",
    "        # append performance data to the logs for later comparison\n",
    "        log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            custom = file,\n",
    "            distribition = model_predictions %>% as.factor() %>% table())\n",
    "\n",
    "        # track what levels are associated with the UUID\n",
    "        add_model_to_manifest(\n",
    "            model_id = model_id,\n",
    "            variables = parse_name(file)\n",
    "        )\n",
    "\n",
    "        # save the model using the model UUID\n",
    "        save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
