{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Calling all models, far and wide!  Now is the time to battle to the DEATH!!!!\n",
    "\n",
    "Just kidding, this is just a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tidyverse\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6      \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.5 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3      \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "Loading required package: compiler\n",
      "\n",
      "Loading required package: raster\n",
      "\n",
      "Loading required package: sp\n",
      "\n",
      "\n",
      "Attaching package: ‘raster’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Loading required package: hsdar\n",
      "\n",
      "Loading required package: rgdal\n",
      "\n",
      "Please note that rgdal will be retired by the end of 2023,\n",
      "plan transition to sf/stars/terra functions using GDAL and PROJ\n",
      "at your earliest convenience.\n",
      "\n",
      "rgdal: version: 1.5-32, (SVN revision 1176)\n",
      "Geospatial Data Abstraction Library extensions to R successfully loaded\n",
      "Loaded GDAL runtime: GDAL 3.4.1, released 2021/12/27\n",
      "Path to GDAL shared files: /usr/share/gdal\n",
      "GDAL binary built with GEOS: TRUE \n",
      "Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821]\n",
      "Path to PROJ shared files: /home/krbundy/.local/share/proj:/usr/share/proj\n",
      "PROJ CDN enabled: FALSE\n",
      "Linking to sp version:1.5-0\n",
      "To mute warnings of possible GDAL/OSR exportToProj4() degradation,\n",
      "use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n",
      "\n",
      "Loading required package: signal\n",
      "\n",
      "\n",
      "Attaching package: ‘signal’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, poly\n",
      "\n",
      "\n",
      "Loading required package: caret\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "Loading required package: Boruta\n",
      "\n",
      "\n",
      "###################################\n",
      "  This is hsdar 1.0.4\n",
      "  To get citation entry type\n",
      "      'citation(\"hsdar\")'\n",
      "###################################\n",
      "\n",
      "\n",
      "Attaching package: ‘hsdar’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    nbands\n",
      "\n",
      "\n",
      "Loading required package: spectrolab\n",
      "\n",
      "spectrolab version: 0.0.17\n",
      "\n",
      "Please cite:\n",
      "Meireles J, Schweiger A, Cavender-Bares J (2017). spectrolab: Class\n",
      "and Methods for Spectral Data in R. doi:10.5281/zenodo.3934575\n",
      "<https://doi.org/10.5281/zenodo.3934575>, R package version 0.0.17,\n",
      "<https://CRAN.R-project.org/package=spectrolab>.DOI: https://doi.org/10.5281/zenodo.3934575\n",
      "\n",
      "\n",
      "Attaching package: ‘spectrolab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:hsdar’:\n",
      "\n",
      "    spectra\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:signal’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    resample\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    sd, smooth, var\n",
      "\n",
      "\n",
      "Loading required package: ranger\n",
      "\n",
      "Loading required package: stringi\n",
      "\n",
      "Loading required package: rjson\n",
      "\n",
      "Loading required package: snow\n",
      "\n",
      "Loading required package: doSNOW\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "\n",
      "Attaching package: ‘foreach’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    accumulate, when\n",
      "\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: rasterVis\n",
      "\n",
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:signal’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# notebooks use their location as their working directory, so\n",
    "# if we are in a subfolder, move to the main folder.  \n",
    "# This however can safely be run multiple times\n",
    "#setwd(M:/lecospec/lecospec)\n",
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)\n",
    "# some features of this notebook will use this in the future, maybe.  I hope so, at least.\n",
    "library(IRdisplay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data file names\n",
    "\n",
    "This loads the data file names.  These are assumed to be the same across training data, labels, test data and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH <- \"Data/gs/\"\n",
    "X_TRAIN_PATH <- paste0(BASE_PATH, \"x_train/\")\n",
    "Y_TRAIN_PATH <- paste0(BASE_PATH, \"y_train/\")\n",
    "\n",
    "X_TEST_PATH <- paste0(BASE_PATH, \"x_test/\")\n",
    "Y_TEST_PATH <- paste0(BASE_PATH, \"y_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "training_data <- list.files(X_TRAIN_PATH)\n",
    "#training_labels <- sort(list.files(\"Data/gs/y_train/\"))# sort alphabetically to keep the files in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"grd_clipped_corrected.csv\" \"grd_clipped_minmax.csv\"   \n",
      " [3] \"grd_clipped_raw.csv\"       \"grd_clipped_robust.csv\"   \n",
      " [5] \"grd_clipped_standard.csv\"  \"grd_dropped_minmax.csv\"   \n",
      " [7] \"grd_dropped_raw.csv\"       \"grd_dropped_robust.csv\"   \n",
      " [9] \"grd_dropped_standard.csv\"  \"grd_imputed_minmax.csv\"   \n",
      "[11] \"grd_imputed_raw.csv\"       \"grd_imputed_robust.csv\"   \n",
      "[13] \"grd_imputed_standard.csv\"  \"grd_raw_corrected.csv\"    \n",
      "[15] \"grd_raw_minmax.csv\"        \"grd_raw_raw.csv\"          \n",
      "[17] \"grd_raw_robust.csv\"        \"grd_raw_standard.csv\"     \n",
      "[19] \"img_clipped_minmax.csv\"    \"img_clipped_raw.csv\"      \n",
      "[21] \"img_clipped_robust.csv\"    \"img_clipped_standard.csv\" \n",
      "[23] \"img_dropped_minmax.csv\"    \"img_dropped_raw.csv\"      \n",
      "[25] \"img_dropped_robust.csv\"    \"img_dropped_standard.csv\" \n",
      "[27] \"img_imputed_minmax.csv\"    \"img_imputed_raw.csv\"      \n",
      "[29] \"img_imputed_robust.csv\"    \"img_imputed_standard.csv\" \n",
      "[31] \"img_raw_minmax.csv\"        \"img_raw_raw.csv\"          \n",
      "[33] \"img_raw_robust.csv\"        \"img_raw_standard.csv\"     \n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load_data <- function(filepath){\n",
    "    data <- list()\n",
    "    train_data_path <- paste0(X_TRAIN_PATH, file)\n",
    "    train_labels_path <- paste0(Y_TRAIN_PATH, file)\n",
    "    test_labels_path <- paste0(Y_TEST_PATH, file)\n",
    "    test_data_path <- paste0(X_TEST_PATH, file)\n",
    "\n",
    "    data$x_train <- read.csv(train_data_path)\n",
    "    data$y_train <- read.csv(train_labels_path)$x %>% as.factor()\n",
    "    data$x_test <- read.csv(test_data_path)\n",
    "    data$y_test <- read.csv(test_labels_path)$x %>% as.factor()\n",
    "\n",
    "    return(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file 'Data/gs/x_test/grd_clipped_corrected.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. load_data(file)",
      "2. read.csv(test_data_path)   # at line 10 of file <text>",
      "3. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "4. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "for(file in training_data){\n",
    "    # load all the data\n",
    "    data <- load_data(file)\n",
    "\n",
    "    model <- ranger::ranger(\n",
    "        num.trees = 1000,\n",
    "        case.weights = targets_to_weights(data$y_train),\n",
    "        classification = TRUE,\n",
    "        x=data$x_train,\n",
    "        y=data$y_train\n",
    "    )\n",
    "\n",
    "    #add forb if it's in the training data to avoid mismatch\n",
    "    if((\"Forb\" %in% levels(data$y_train)) && !(\"Forb\"  %in% levels(data$y_test))){\n",
    "        levels(data$y_test) <- c(levels(data$y_test, \"Forb\"))\n",
    "        }\n",
    "\n",
    "    # create predictions (ranger)\n",
    "    model_predictions <- predict(\n",
    "        model, \n",
    "        data$x_test\n",
    "    )$prediction %>% as.factor()\n",
    "\n",
    "    # generate the confusion matrix\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        model_predictions, \n",
    "        test_samples,\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "    # generate an id to uniquely identify the model\n",
    "    model_id <- uuid::UUIDgenerate()\n",
    "\n",
    "    # append performance data to the logs for later comparison\n",
    "    log_model_results(\n",
    "        model_id = model_id,\n",
    "        confusion_matrix = confusion_matrix,\n",
    "        distribition = model_predictions %>% as.factor() %>% table())\n",
    "\n",
    "    # track what levels are associated with the UUID\n",
    "    add_model_to_manifest(\n",
    "        model_id = model_id,\n",
    "        variables = parse_name(file)\n",
    "    )\n",
    "\n",
    "    # save the model using the model UUID\n",
    "    save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- ranger::ranger(\n",
    "        num.trees = 1000,\n",
    "        case.weights = weights_by_pft,\n",
    "        classification = TRUE,\n",
    "        x=df,\n",
    "        y=gs_train_labels[[i]]\n",
    "    )\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    model_predictions <- predict(\n",
    "        model, \n",
    "        test_df\n",
    "    )$prediction %>% as.factor()\n",
    "    \n",
    "    test_samples <- gs_samples[[i]] %>% as.factor()\n",
    "    if(!(\"Forb\" %in% levels(test_samples))){\n",
    "\n",
    "        levels(test_samples) <- c(levels(test_samples), \"Forb\")\n",
    "    }\n",
    "\n",
    "    confusion_matrix <- caret::confusionMatrix(\n",
    "        model_predictions, \n",
    "        test_samples,\n",
    "        mode = \"everything\"\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    model_metadata <- list(\n",
    "        uuid = model_id,\n",
    "        variables = colnames(df),\n",
    "        type = \"Random Forest (Ranger)\",\n",
    "        preprocessing = gs_preprocessing[[i]],\n",
    "        saved = paste0(\"mle/models/gs/\", model_id, \".rda\"),\n",
    "        results = paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "    )\n",
    "\n",
    "    metadata_save_path <- paste0(\"mle/metadata/\", model_id, \".json\")\n",
    "    json_metadata_str <- rjson::toJSON(model_metadata)\n",
    "    write(json_metadata_str, file=metadata_save_path)\n",
    "    \n",
    "    save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "parse_name <- function(filepath){\n",
    "    name_no_extension <- stringi::stri_replace_all(filepath, \"\", \".csv\", fixed = TRUE)\n",
    "    name_parts <- stringi::stri_split(name_no_extension, \"_\", fixed = TRUE)\n",
    "\n",
    "    variables <- list(\n",
    "        source = name_parts[[1]]\n",
    "    )\n",
    "\n",
    "    if(length(name_parts) > 1){\n",
    "        variables$outliers <- names_parts[[2]]\n",
    "    } else {\n",
    "        variables$outliers <- NULL\n",
    "    }\n",
    "\n",
    "    if(length(name_parts) > 2){\n",
    "        variables$preprocessing <- name_parts[[3]]\n",
    "    } else {\n",
    "        variables$preprocessing <- NULL\n",
    "    }\n",
    "\n",
    "    return(variables)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(model_id, variables, logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- paste(names(variables), \"model_id\\n\", sep=\",\")\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        variables$source,\n",
    "        variables$outliers,\n",
    "        variables$preprocessing,\n",
    "        model_id,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \"\\n\")\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: Ranger (Random Forest)\"))\n",
    "    print(paste0(\"Data Index: \",i))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)model_predictions %>% as.factor() %>% table()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
