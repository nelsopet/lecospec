{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!dir.exists(\"Functions/\")){\n",
    "    setwd(\"../\")\n",
    "    if(!dir.exists(\"Functions\")){\n",
    "        setwd(\"M:/lecospec/lecospec/\")\n",
    "    }\n",
    "}\n",
    "source(\"Functions/lecospectR.R\", echo = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "log_model_results <- function(model_id, confusion_matrix, distribition, custom = NULL, logpath = \"./gs.log\"){\n",
    "    # append performance data to the logs for later comparison\n",
    "    sink(file = logpath, append = TRUE)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"---------------------- Model Data ---------------------\")\n",
    "    \n",
    "    print(paste0(\"Model Type: Ranger (Random Forest)\"))\n",
    "    print(paste0(\"Data Index: \",custom))\n",
    "    print(paste0(\"Model UUID: \", model_id))\n",
    "    print(\"---------------------- Confusion Matrix ---------------------\")\n",
    "    print(confusion_matrix)\n",
    "    print(\"---------------------- Class Distribution ---------------------\")\n",
    "    print(distribition)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    sink(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_model_to_manifest <- function(\n",
    "    model_id, \n",
    "    outlier = \"\", \n",
    "    preprocessing=\"\",\n",
    "    source=\"\", \n",
    "    weight = \"\",\n",
    "    logpath=\"./gs_manifest.csv\"){\n",
    "    if(!file.exists(logpath)){\n",
    "        header <- \"source,outliers,preprocessing,weight,model_id\"\n",
    "        write(header, file = logpath)\n",
    "    }\n",
    "\n",
    "    line <- paste(\n",
    "        source,\n",
    "        outlier,\n",
    "        preprocessing,\n",
    "        weight,\n",
    "        sep=\",\"\n",
    "    )\n",
    "    line <- paste0(line, \",\", model_id)\n",
    "\n",
    "    write(line, file=logpath, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_model <- function(\n",
    "    train_df, \n",
    "    train_labels,\n",
    "    test_df, \n",
    "    test_labels,\n",
    "    outlier_fn = NULL,\n",
    "    preprocess_fn = NULL,\n",
    "    weight_fn = targets_to_weights,\n",
    "    model_id = uuid::UUIDgenerate(),\n",
    "    ignore_cols = NULL,\n",
    "    seed = NULL\n",
    "){\n",
    "    if(!is.null(seed)){\n",
    "        set.seed(seed)\n",
    "    }\n",
    "\n",
    "    x_train <- train_df %>% as.data.frame()\n",
    "    if(is.function(outlier_fn)){\n",
    "        x_train <- outlier_fn(x_train)\n",
    "    }\n",
    "    if(is.function(preprocess_fn)){\n",
    "        x_train <- preprocess_fn(x_train)\n",
    "    }\n",
    "\n",
    "    model <- ranger::ranger(\n",
    "            num.trees = 1000,\n",
    "            case.weights = weight_fn(train_labels),\n",
    "            classification = TRUE,\n",
    "            x=x_train,\n",
    "            y=train_labels\n",
    "        )\n",
    "\n",
    "    if((\"Forb\" %in% levels(train_labels)) && !(\"Forb\"  %in% levels(test_labels))){\n",
    "            levels(test_labels) <- c(levels(test_labels), \"Forb\")\n",
    "            }\n",
    "\n",
    "    # create predictions (ranger)\n",
    "        model_predictions <- predict(\n",
    "            model, \n",
    "            test_df\n",
    "        )$prediction %>% as.factor()\n",
    "\n",
    "        # generate the confusion matrix\n",
    "\n",
    "        confusion_matrix <- caret::confusionMatrix(\n",
    "            model_predictions, \n",
    "            test_labels,\n",
    "            mode = \"everything\"\n",
    "        )\n",
    "\n",
    "        # generate an id to uniquely identify the model\n",
    "        #model_id <- uuid::UUIDgenerate()\n",
    "\n",
    "        # append performance data to the logs for later comparison\n",
    "        log_model_results(\n",
    "            model_id = model_id,\n",
    "            confusion_matrix = confusion_matrix,\n",
    "            #custom = file,\n",
    "            distribition = model_predictions %>% as.factor() %>% table())\n",
    "\n",
    "        # track what levels are associated with the UUID\n",
    "\n",
    "        # save the model using the model UUID\n",
    "        save(model, file = paste0(\"mle/models/gs/\", model_id, \".rda\"))\n",
    "        \n",
    "        return(model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "base_paths <- c(\n",
    "    \"grd_raw_raw.csv\",\n",
    "    \"grd_raw_corrected.csv\",\n",
    "    \"img_raw_raw.csv\",\n",
    "    \"img_indices_only.csv\",# include veg indices\n",
    "    \"grd_indices_only.csv\"\n",
    ")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculate_posterior_weights <- function(validation_path =\"figures/merged_validation_s.csv\" ){\n",
    "\n",
    "    validation_df <- read.csv(validation_path, header = TRUE)\n",
    "    #print(head(validation_df))\n",
    "\n",
    "    total_observations <- sum(validation_df$validation_counts)\n",
    "    #print(total_observations)\n",
    "    weights <- (1/ validation_df$validation_prop)\n",
    "    #print(validation_df$validation_prop)\n",
    "\n",
    "    total_by_fg1 <- aggregate(\n",
    "        x = validation_df$validation_counts,\n",
    "        by = list(validation_df$key),\n",
    "        FUN = sum\n",
    "    )\n",
    "\n",
    "    fg1_weight_list <- list()\n",
    "\n",
    "    for( row_idx in seq(nrow(total_by_fg1))){\n",
    "        name <- total_by_fg1$Group.1[[row_idx]]\n",
    "        value <- total_by_fg1$x[[row_idx]]\n",
    "        fg1_weight_list[name] <- value\n",
    "    }\n",
    "    \n",
    "    return(fg1_weight_list)\n",
    "}\n",
    "\n",
    "get_posterior_weights_from_targets <- function(target_factor, posterior_weight = calculate_posterior_weights()){\n",
    "    unbiased_weights <- targets_to_weights(target_factor)\n",
    "\n",
    "    target_name_char <- target_factor %>% as.character()\n",
    "\n",
    "    output_weights <- seq_along(target_factor)\n",
    "\n",
    "    for(i in seq_along(target_factor)){\n",
    "        if(posterior_weight[[target_name_char[[i]]]] > 0){\n",
    "            fg1_weight <- 1 / posterior_weight[[target_name_char[[i]]]]\n",
    "        } else {\n",
    "            fg1_weight <- 0\n",
    "        }\n",
    "        output_weights[[i]] <- unbiased_weights[[i]] * fg1_weight\n",
    "    }\n",
    "\n",
    "    return(output_weights)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test_p_weight <- calculate_posterior_weights()\n",
    "test_p_weight \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "outlier_functions <- list(\n",
    "    clip = load_model(\"./mle/clip_transform.rda\"),\n",
    "    no_treatment = function(x){return(x)}# no transform\n",
    ")\n",
    "\n",
    "outlier_treatments <- c(\n",
    "    \"clip\",\n",
    "    \"no_treatment\"\n",
    ")\n",
    "\n",
    "preprocess_functions <- list(\n",
    "    no_treatment = function(x){return(x)},# no transform\n",
    "    min_max = columnwise_min_max_scale,\n",
    "    robust = columnwise_robust_scale,\n",
    "    standard = standardize_df\n",
    ")\n",
    "\n",
    "weight_functions <- list(\n",
    "    posterior = get_posterior_weights_from_targets,\n",
    "    balanced = targets_to_weights,\n",
    "    no_treatment = function(x){return(NULL)}# No weights\n",
    ")\n",
    "weight_treatments <- c(\n",
    "    \"no_treatment\",\n",
    "    \"balanced\",\n",
    "    \"posterior\"\n",
    ")\n",
    "\n",
    "preprocessing_treatments <- c(\n",
    "    \"no_treatment\",\n",
    "    \"min_max\",\n",
    "    \"robust\",\n",
    "    \"standard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test_data <- read.csv(\"Data/gs/x_test/img_raw_raw.csv\")\n",
    "test_labels <- read.csv(\"Data/gs/y_test/img_raw_raw.csv\")$x %>% as.factor()\n",
    "#train_labels <- read.csv(\"Data/gs/y_train/img_raw_raw.csv\")$x %>% as.factor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(filepath in base_paths){\n",
    "    train_data <- subset(read.csv(paste0(\"Data/gs/x_train/\", filepath)), select = -c(X))\n",
    "    labels <- read.csv(paste0(\"Data/gs/y_train/\", filepath))$x %>% as.factor()\n",
    "\n",
    "    for(o_treatment in outlier_treatments){\n",
    "        for(p_treatment in preprocessing_treatments){\n",
    "            for(w_treatment in weight_treatments){\n",
    "\n",
    "\n",
    "                model_id <- uuid::UUIDgenerate()\n",
    "                save_path <- paste0(\"mle/experiments/gs/\", model_id, \"/\")\n",
    "                if(!dir.exists(save_path)){\n",
    "                    dir.create(save_path)\n",
    "                } \n",
    "\n",
    "                rf_model <- train_model(\n",
    "                    train_data, \n",
    "                    labels, \n",
    "                    test_data,\n",
    "                    test_labels,\n",
    "                    outlier_fn = outlier_functions[[o_treatment]],\n",
    "                    preprocess_fn = preprocess_functions[[p_treatment]],\n",
    "                    weight_fn = weight_functions[[w_treatment]],\n",
    "                    model_id = model_id\n",
    "                )\n",
    "\n",
    "                add_model_to_manifest(\n",
    "                    model_id = model_id,\n",
    "                    outlier = o_treatment,\n",
    "                    preprocessing = p_treatment,\n",
    "                    source = filepath,\n",
    "                    weight = w_treatment,\n",
    "                    logpath=\"./gs_manifest_3.csv\"\n",
    "                )\n",
    "\n",
    "                results <- validate_model(\n",
    "                    rf_model, \n",
    "                    save_path, \n",
    "                    outlier_processing = \"none\",\n",
    "                    transform_type = \"none\",\n",
    "                )\n",
    "\n",
    "                aggregated_results <- aggregate_results(save_path)\n",
    "\n",
    "                plot_by_pft(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"aggregate.html\"),\n",
    "                    open = FALSE\n",
    "                )\n",
    "            #\n",
    "                write_validation_table(\n",
    "                    aggregated_results,\n",
    "                    save_path = paste0(save_path, \"table.html\"),\n",
    "                    open = FALSE\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
